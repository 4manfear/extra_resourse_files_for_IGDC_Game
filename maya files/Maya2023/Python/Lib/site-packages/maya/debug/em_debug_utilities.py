import maya
maya.utils.loadStringResourcesForModule(__name__)

'''
Collection of utilities to support debug output for various views into the evaluation manager data
'''

__all__ = [ 'dbg_nodes'
          , 'dbg_graph'
          , 'dbg_scheduling_graph'
          , 'dbg_scheduling_types'
          , 'convert_exception_to_unicode'
          , 'dbg_graph_to_dot'
          , 'dbg_scheduling_graph_to_dot'
          , 'get_default_directory'
          , 'get_minimal_scene_objects_from'
          , 'open_file'
          , 'require_evaluation_graph'
          , 'get_custom_evaluator_clusters'
          , 'get_all_custom_evaluators_clusters'
          , 'print_deformer_clusters'
          , 'dotFormatting'
          ]

import json
import locale
import maya.cmds as cmds
from functools import wraps
from maya.debug.emModeManager import emModeManager
from builtins import str as futureStr

DOWNSTREAM_LINK = '[]-->'
UPSTREAM_LINK = '-->[]'
PLUG_TYPES = { 'input' : UPSTREAM_LINK, 'output' : DOWNSTREAM_LINK, 'affectsWorld' : '[-W>]', 'attributes' : '[---]' }

# Message to give when generation of the EG or SG information fails due to the graph not yet existing
GRAPH_NOT_AVAILABLE = maya.stringTable['y_maya_debug_em_debug_utilities.kEGNotAvailable' ]

# Colors in hex format. taken from https://brand.autodesk.com/brand-elements/colors
WHITE = '#FFFFFF'
BLACK = '#000000'
GREEN = '#87BC40'
YELLOW_ORANGE = '#FAA21B'

#======================================================================
def convert_exception_to_unicode(exception):
    """
    :return: a string representing the exception, in Unicode format.

    It handles cases such as when WindowsError exceptions contain Unicode
    characters encoded in a regular string in the OS encoding.  It does
    so in a slightly more generic and robust way by also trying the
    system's locale encoding.
    """
    message = str(exception)
    
    # MAYA-105821: Python 3 strings are Unicode by default
    from sys import version_info as sys_version_info
    if sys_version_info[0] >= 3:
        return message
    else:
        from sys import getdefaultencoding as sys_getdefaultencoding
        encodings_to_try = [
            [],
            [sys_getdefaultencoding()],
            [locale.getpreferredencoding()],
            ]
        for encoding in encodings_to_try:
            try:
                return message.decode(*encoding)
            except UnicodeDecodeError:
                pass

    # Nothing worked, resort to repr()
    return futureStr(repr(message))

#======================================================================
def collapse_lists(list_of_items):
    '''
    Convert a list of mixed strings and other iterables to a list of unique items
    :param list_of_items: List consisting of strings, tuples, or other lists to be collapsed
    :return: List consisting of unique strings that were somewhere in the input list structure
    '''
    result_list = []
    for item in list_of_items or []:
        if not isinstance(item,(tuple,list,set)):
            result_list.append( str(item) )
        else:
            result_list += [sub_item for sub_item in item]
    # Make it a unique list before returning
    return list(set(result_list))

#======================================================================
def dbpeek_selection_expansion(expansion_type, use_selection, selection_depth, peek_args):
    '''
    Take the current configuration and figure out the parameters required by the dbpeek
    command to handle the selection.
    The two selection settings are the All/Selected boolean, and the integer depth. When
    "All" is selected every node is used, otherwise the selection is expanded "depth" steps and
    the expanded selection list is returned (without actually changing the selection).

    :param expansion_type: Type of graph for selection expansion, if needed (DG, SG, or DG)
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :param peek_args: Initial arguments in use by the dbpeek command, modified to include
                         any extra arguments required to respect the current selection settings

    :return: List of the expanded selection, empty list if using all nodes
    '''
    selection = []
    if not use_selection:
        peek_args['all'] = True
    else:
        # The expansion happens even when the depth is 0 because it will expand within a
        # cluster to include all nodes in the same cluster.
        selected = cmds.ls(sl=True)
        if len(selected or []) > 0:
            selection = collapse_lists( cmds.expandedSelection( cmds.ls(sl=True), expansionType=expansion_type, depth=selection_depth ) )
            if len(selection) == 0:
                raise RuntimeError( maya.stringTable['y_maya_debug_em_debug_utilities.kIrrelevantSelection'] )
        else:
            raise RuntimeError( maya.stringTable['y_maya_debug_em_debug_utilities.kEmptySelection'] )

    return selection

#======================================================================
def dbg_nodes(summary_only, include_plugs, use_selection, selection_depth):
    '''
    Generate a string representing the evaluation graph nodes.
    :param summary_only: If True then just summarize the information rather than using JSON format
    :param include_plugs: If True then include the lists of dirty plugs the evaluation node knows about
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :return: Evaluation node structure in string form, None if the graph was not available
    '''

    # if the graph is not valid then don't try to display it
    if not cmds.evaluationManager( query=True, invalidate=True ):
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['nodes'] }
    if include_plugs:
        peek_args['argument'].append( 'plugs' )
    selection = dbpeek_selection_expansion( 'EG', use_selection, selection_depth, peek_args )
    results = cmds.dbpeek( selection, **peek_args )

    if summary_only:
        node_data = json.loads( results )
        results = ''
        if include_plugs:
            plug_list = node_data['plugs']
            node_list = list(plug_list.keys())
            for node in sorted(node_list):
                results += '{}\n'.format( node )
                for plug_type, plug_decoration in list(PLUG_TYPES.items()):
                    for plug in sorted(plug_list[node][plug_type]):
                        results += '    {} {}\n'.format( plug_decoration, plug )
        else:
            for node in sorted(node_data['nodes']):
                results += '{}\n'.format(node)

    return results

#======================================================================
def dbg_graph(summary_only, include_plugs, use_selection, selection_depth):
    '''
    Generate a string representing the evaluation graph nodes and connections.
    :param summary_only: If True then just summarize the information rather than using JSON format
    :param include_plugs: If True then include the lists of dirty plugs the evaluation node knows about
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :return: Evaluation graph structure in string form
    :raise RuntimeError: if the graph was not available
    '''

    # if the graph is not valid then don't try to display it
    if not cmds.evaluationManager( query=True, invalidate=True ):
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['connections'] }
    if include_plugs:
        peek_args['argument'].append( 'plugs' )
    selection = dbpeek_selection_expansion( 'EG', use_selection, selection_depth, peek_args )
    results = cmds.dbpeek( selection, **peek_args )

    if summary_only:
        try:
            json_results = json.loads( results )
            graph_data = json_results['connections']
        except ValueError:
            raise RuntimeError( maya.stringTable['y_maya_debug_em_debug_utilities.kNoConnectionData' ] )
        results = ''
        plugs = {}
        if include_plugs and (len(graph_data) > 0):
            try:
                plugs = json_results['plugs']
            except ValueError:
                raise RuntimeError( maya.stringTable['y_maya_debug_em_debug_utilities.kNoPlugData' ] )
        for node in sorted(graph_data.keys()):
            node_connections = graph_data[node]
            results += '{}\n'.format( node )
            #--------------------
            downstream_list = []
            for downstream in node_connections['downstream']:
                downstream_list += list(downstream.values())
            for downstream_node in downstream_list:
                results += '    --> {}\n'.format(downstream_node)
            #--------------------
            upstream_list = []
            for upstream in node_connections['upstream']:
                upstream_list += list(upstream.keys())
            for upstream_node in upstream_list:
                results += '    <-- {}\n'.format(upstream_node)
            #--------------------
            if node in plugs:
                results += '    Plugs\n'
                for plug_type, plug_decoration in list(PLUG_TYPES.items()):
                    for plug in sorted(plugs[node][plug_type]):
                        results += '        {} {}\n'.format( plug_decoration, plug )

    return results

#======================================================================
def dbg_scheduling_graph(summary_only, include_clusters, use_selection, selection_depth):
    '''
    Generate a string representing the scheduling graph structure
    :param summary_only: If True then just summarize the information rather than using JSON format
    :param include_clusters: If True then include the members of each cluster rather than just a membership size
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :return: Scheduling graph structure in string form
    :raise RuntimeError: if the graph was not available
    '''

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['scheduling','verbose'] }
    selection = dbpeek_selection_expansion( 'SG', use_selection, selection_depth, peek_args )
    scheduling_data = cmds.dbpeek( selection, **peek_args )

    try:
        # Since accessing dictionary values doesn't create copies setting up these temporary
        # variables is cheap, and serves to validate the input
        scheduling_json = json.loads(scheduling_data)['scheduling']
        edges = scheduling_json['edges']
        evaluation = scheduling_json['executionOrder']
        clusters = scheduling_json['clusters']
    except Exception:
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    if summary_only:
        # Only downstream connections are in the data. Create the reverse connection
        # list as well before dumping.
        upstream_nodes = {}
        for node, downstream_nodes in list(edges.items()):
            for downstream_node in downstream_nodes:
                upstream_nodes[downstream_node] = upstream_nodes.get( downstream_node, [] ) + [node]

        # Dump in a format similar to the evaluation graph, with each node appearing
        # alphabetically, along with its input and output connections. In the case of the
        # scheduling graph a "node" could be a cluster. When the include_clusters flag is
        # set those will include the cluster members, similar to how dirty plugs are included in
        # the evaluation graph dump.
        results = ''
        for node, downstream_nodes in list(edges.items()):
            results += '{}\n'.format(node)
            for downstream_node in downstream_nodes:
                results += '    {} {}\n'.format(DOWNSTREAM_LINK, downstream_node)
            if node in upstream_nodes:
                for upstream_node in upstream_nodes[node]:
                    results += '    {} {}\n'.format(UPSTREAM_LINK, upstream_node)
            if include_clusters:
                # For some reason the cluster is named differently in the cluster list
                cluster_name = node.replace( "Cluster_", "", 1 )
                if cluster_name in clusters:
                    results += '    Cluster Contains: [\n'
                    for cluster_node in clusters[cluster_name]:
                        results += '      {}\n'.format( cluster_node )
                    results += '    ]\n'
    else:
        raw_json = { 'scheduling' : { 'executionOrder' : evaluation } }
        if include_clusters:
            raw_json['scheduling']['clusters'] = clusters
        results = json.dumps( raw_json, indent=4, separators=(',', ': ') )

    return results

#======================================================================
def dbg_scheduling_types(summary_only, use_selection, selection_depth):
    '''
    Generate a string representing the scheduling types of nodes
    :param summary_only: If True then just summarize the information rather than using JSON format
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :return: String containing the scheduling type information
    :raise RuntimeError: if the graph was not available
    '''

    # These types match the JSON keys provided by the dbpeek command
    scheduling_types = ['Parallel', 'Serial', 'GloballySerial', 'Untrusted']

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['scheduling', 'verbose'] }
    selection = dbpeek_selection_expansion( 'SG', use_selection, selection_depth, peek_args )
    scheduling_data = cmds.dbpeek( selection, **peek_args )

    try:
        scheduling_info = {k:v for k, v in list(json.loads( scheduling_data )['scheduling']['scheduling'].items()) if k in scheduling_types }
    except ValueError:
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    if summary_only:
        results = ''
        for scheduling_type, scheduling_list in list(scheduling_info.items()):
            if len(scheduling_list) > 0:
                results += '{}\n'.format( scheduling_type )
                for node in sorted(scheduling_list):
                    results += '    {}\n'.format( node )
    else:
        results = json.dumps( { 'scheduling' : scheduling_info }, indent=4, separators=(',', ': ') )

    return results

#======================================================================
def dbg_graph_to_dot(include_plugs, use_selection, selection_depth, out_dot):
    '''
    Generate a string representing the evaluation graph nodes and connections in a DOT visualization format.
    :param include_plugs: If True then include the lists of dirty plugs the evaluation node knows about
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :param out_dot: File where the .dot format data should go
    :return: Full path to the .dot file location
    :raise RuntimeError: if the graph was not available
    '''

    # if the graph is not valid then don't try to display it
    if not cmds.evaluationManager( query=True, invalidate=True ):
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['connections', 'dot'] }
    peek_args['outputFile'] = out_dot
    if include_plugs:
        peek_args['argument'] += ['verbose']
    selection = dbpeek_selection_expansion( 'EG', use_selection, selection_depth, peek_args )

    try:
        cmds.dbpeek( selection, **peek_args )
    except Exception as ex:
        raise RuntimeError( str(ex) )

    return out_dot

#======================================================================
def dbg_scheduling_graph_to_dot(include_clusters, use_selection, selection_depth, out_dot):
    '''
    Generate a string representing the evaluation graph nodes and connections in a DOT visualization format.
    :param include_clusters: If True then include the members of each cluster rather than just a membership size
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :param out_dot: File where the .dot format data should go
    :return: Full path to the .dot file location
    :raise RuntimeError: if the graph was not available
    '''

    # if the graph is not valid then don't try to display it
    if not cmds.evaluationManager( query=True, invalidate=True ):
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['scheduling', 'dot'] }
    peek_args['outputFile'] = out_dot
    if include_clusters:
        peek_args['argument'] += ['verbose']
    selection = dbpeek_selection_expansion( 'SG', use_selection, selection_depth, peek_args )

    try:
        cmds.dbpeek( selection, **peek_args )
    except Exception as ex:
        raise RuntimeError( str(ex) )

    return out_dot

#======================================================================
def dbg_deformations_to_dot(graphInfo, include_plugs, out_dot):
    '''
    Generate a string representing the deformation graph nodes and connections in a DOT visualization format.
    :param graphInfo: JSON object that describes the deformation graph
    :param out_dot: File where the .dot format data should go
    :raise RuntimeError: if writing to out_dot fails
    '''

    if 'error' in graphInfo:
        raise RuntimeError( graphInfo['error'] )
    elif 'clusters' not in graphInfo:
        # Unexpected JSON structure
        raise RuntimeError( maya.stringTable['y_maya_debug_em_debug_utilities.kUnexpectedJSONFormat' ] )

    formatHelper = dotFormatting()

    # node formats
    nodeBaseFormat = '[shape="box" style="rounded" color="{}"]'
    filterFormat = nodeBaseFormat.format(BLACK)
    staticFormat = nodeBaseFormat.format(GREEN)
    animatedFormat = nodeBaseFormat.format(YELLOW_ORANGE)

    connectionFormat = '[label = "{0} -> {1}"]'

    dot = formatHelper.header(label='DeformationGraph', direction='LR', include_sizing=False)

    # legend
    dot += ('\n\tsubgraph cluster_legend {'
            '\n\t\tlabel = "Legend";'
            '\n\t\tshape = "record";'
            '\n\t\tstyle = "dashed";'
            '\n\t\t"Static Chain Input" ' + staticFormat + ';'
            '\n\t\t"Animated Chain Input" ' + animatedFormat + ';'
            '\n\t\t"Filter Node" ' + filterFormat + ';'
            '\n\t}\n'
            )

    registeredInputs = []

    staticInputs = ''
    animatedInputs = ''
    filters = ''
    connections = ''

    # Add nodes and connections
    for cluster in (graphInfo.get('clusters', [])):
        for chain in (cluster.get('chains', [])):
            for node in (chain.get('nodes', [])):
                if 'type' in node and 'name' in node:
                    if node['type'] == 'staticInput':
                        registeredInputs.append(node['name'])
                        staticInputs += formatHelper.node(node['name'], nodeFormat=staticFormat)
                    elif node['type'] == 'animatedInput':
                        registeredInputs.append(node['name'])
                        animatedInputs += formatHelper.node(node['name'], nodeFormat=animatedFormat)
                    elif node['type'] == 'filter' and node['name'] not in registeredInputs:
                        filters += formatHelper.node(node['name'], nodeFormat=filterFormat)

                    if 'destinationNode' in node:
                        if include_plugs and 'sourcePlug' in node and 'destinationPlug' in node:
                            format = connectionFormat.format(node['sourcePlug'], node['destinationPlug'])
                            connections += formatHelper.connection(node['name'], node['destinationNode'], connectionFormat=format)
                        else:
                            connections += formatHelper.connection(node['name'], node['destinationNode'])

    dot += staticInputs + animatedInputs + filters + connections + formatHelper.footer();

    # Write to DOT file
    try:
        with open(out_dot, 'w') as file:
            file.write(dot)
    except IOError as ex:
        raise RuntimeError( convert_exception_to_unicode(ex) )

#======================================================================
def require_evaluation_graph(func):
    """
    This decorator makes sure that the given function will have a valid
    evaluation graph.
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        '''Define a wrapper to validate the evaluation graph before running the function'''
        # Make sure evaluation manager is active.
        mode_mgr = emModeManager()
        if 'off' == mode_mgr.mode:
            cmds.error( maya.stringTable['y_maya_debug_em_debug_utilities.kEvaluationManagerNotActive' ] )
            return

        if mode_mgr.invalid:
            # The graph is not ready.
            mode_mgr.invalid = True

            # Sometimes anim curves may decide to invalidate the graph so do it again.
            if mode_mgr.invalid:
                mode_mgr.invalid = True

        # We should have a valid evaluation graph.  If that is not the case,
        # we let the function go through anyways and let it catch the error.
        return func(*args, **kwargs)

    return wrapper

#======================================================================
def open_file(file_name):
    """
    Open up an output file with the application assigned to it by the OS.

    :param file_name: File to be opened up (usually a PDF or DOT file but can be any recognized format)
    """
    import os
    try:
        from sys import platform as sys_platform
        if sys_platform == 'win32':
            os.startfile(file_name)
        else:
            opener = 'open' if sys_platform == 'darwin' else 'xdg-open'
            from subprocess import call as subprocess_call
            subprocess_call([opener, file_name])
    except Exception as ex:
        message = maya.stringTable['y_maya_debug_em_debug_utilities.kErrorFileOpen' ]
        cmds.error( message.format(file_name, convert_exception_to_unicode(ex)))
        return

#======================================================================
def get_default_directory():
    '''Get a reasonable default directory for temporary output.'''
    from os import getenv as os_getenv, path as os_path
    default_path = os_getenv('MAYA_DEBUG_DIRECTORY')
    if default_path is None:
        from tempfile import gettempdir as tempfile_gettempdir
        default_path = tempfile_gettempdir()
    return os_path.normpath( default_path )

#======================================================================
# The following methods are used to get the minimal dependencies.
# Only get_minimal_scene_objects_from() is exposed
def get_upstream_set(starting_nodes):
    '''
    Find all nodes one step upstream from the starting_nodes
    :param starting_nodes: Initial nodes from which to go upstream
    :return: Unique list of the starting_nodes plus any nodes one step upstream from them
    '''
    cmds.select(clear=True)

    upstream_set = set(starting_nodes)
    nodes_to_process = []
    nodes_to_process.extend(starting_nodes)

    while len(nodes_to_process) > 0:
        node = nodes_to_process.pop()
        parentList = cmds.evaluationManager(upstreamFrom=node) or []
        cycleList = cmds.evaluationManager(cycleCluster=node) or []
        for oneParent in parentList:
            if oneParent not in upstream_set:
                upstream_set.add(oneParent)
                nodes_to_process.append(oneParent)
        for oneParent in cycleList:
            if oneParent not in upstream_set:
                upstream_set.add(oneParent)
                nodes_to_process.append(oneParent)

    return list(upstream_set)

#======================================================================
def expand_to_upstream_hierarchy(input_list):
    '''
    Traverse upstream through the evaluation graph to find nodes related
    to those in the starting_nodes list.
    :param starting_nodes: Initial nodes from which to go upstream
    :return: Unique list of all nodes upstream from and including the starting_nodes
    '''
    return_set = set()

    nodes_to_process = []
    nodes_to_process.extend(input_list)

    while len(nodes_to_process) > 0:
        node = nodes_to_process.pop()
        return_set.add(node)

        parentList = cmds.listRelatives(node, fullPath=True, parent=True) or []
        for parentNode in parentList:
            if parentNode not in return_set:
                nodes_to_process.append(parentNode)

    return list(return_set)

#======================================================================
def expand_to_shapes(input_list):
    '''
    Expand an input_list to include all shapes below them in the DAG
    :param input_list: List of nodes for which shapes are to be added
    :return: Input list plus any shapes below transforms that appear in the input_list
    '''
    shapes = set()
    for node in input_list:
        nodeType = cmds.nodeType(node)

        if nodeType == 'transform':
            shape_list = cmds.listRelatives(node, fullPath=True, shapes=True) or []
            for shape_node in shape_list:
                shapes.add(shape_node)
    expanded_list = list(shapes) + input_list
    return expanded_list

#======================================================================
def get_minimal_scene_objects_from(input_list):
    '''
    :param input_list: List of nodes that are required in the minimal scene
    :return: List of nodes required in order to correctly evaluate the nodes in input_list
    '''
    upstream = get_upstream_set(input_list)
    upstream_with_dag = expand_to_upstream_hierarchy(upstream)
    upstream_with_dag_and_shapes = expand_to_shapes(upstream_with_dag)
    return upstream_with_dag_and_shapes

#======================================================================
def select_inverse_visible_dag_objects(original_nodes):
    '''Create an inverse selection list from the specified original nodes'''

    if len(original_nodes) == 0:
        # Nothing was selected, so there is nothing to do...
        return

    cmds.select(original_nodes)

    # Determine if we have any visible selected dag objects, otherwise
    # there is nothing to do
    objects = cmds.ls(dagObjects=True, visible=True, selection=True)

    if len(objects) != 0:
        # Inverse: Remove all visible dagObjects in our original list from
        # the selection and add all the invisible ones
        cmds.select(toggle=True, allDagObjects=True, visible=True)

        # Deselect the parents and select any unneeded siblings
        parents = cmds.listRelatives(original_nodes, parent=True, path=True)
        if parents:
            if len(parents) > 0:
                # Remove all parents from in our original list from the selection
                cmds.select(parents, deselect=True)
                children = cmds.listRelatives(parents, children=True, path=True)
                cmds.select(children, add=True)

        # make sure the original objects in the original list are not selected
        cmds.select(original_nodes, deselect=True)

#======================================================================
def get_custom_evaluator_clusters(evaluator):
    """
    Get the clusters for a given custom evaluator, if any.
    """

    clustersAsList = cmds.evaluator(query=True, clusters=True, name=evaluator)
    if not clustersAsList:
        return []

    evaluatorClusters = []
    i = 0
    while i < len(clustersAsList):
        elementCount = int(clustersAsList[i])
        currentCluster = clustersAsList[(i + 1): (i + 1 + elementCount)]
        evaluatorClusters.append(currentCluster)
        i += 1 + elementCount

    return evaluatorClusters

#======================================================================
def get_all_custom_evaluators_clusters():
    """
    Get the clusters for all custom evaluators, if any.
    """

    clusters = {}

    evaluators = cmds.evaluator(query=True)
    for evaluator in evaluators:
        evaluatorClusters = get_custom_evaluator_clusters(evaluator)
        if not evaluatorClusters:
            continue

        clusters[evaluator] = evaluatorClusters

    return clusters

#======================================================================
def print_deformer_clusters():
    """
    Print out any clusters of nodes captured by the deformer evaluator.
    """

    evaluators = cmds.evaluator(query=True)
    if 'deformer' in evaluators:
        clusters = get_custom_evaluator_clusters('deformer')
        if clusters:
            print(clusters)
        else:
            cmds.warning(maya.stringTable['y_maya_debug_em_debug_utilities.kNoDeformerCluster' ])
    else:
        cmds.warning(maya.stringTable['y_maya_debug_em_debug_utilities.kDeformerEvaluatorError' ])

#======================================================================
class dotFormatting(object):
    """
    Helper class to provide DOT language output support.
    """

    @staticmethod
    def header(label='', direction='UD', include_sizing=True):
        """Returns the string for a header defining the basic graph layout"""
        dot = 'digraph G\n{{\n\tlabel="{}" ;\n\trankdir="{}" ;'.format(label, direction)
        if include_sizing: dot += dotFormatting.scale()
        return dot

    @staticmethod
    def scale():
        """Returns a string containing default sizing information"""
        return '\n\tnslimit = 1.0 ;\n\tsize = "7.5,10" ;\n\tdpi = 600 ;\n\toverlap = scale;\n'

    @staticmethod
    def footer():
        """Closes out the body section"""
        return '}\n'

    @staticmethod
    def node(node, nodeFormat='', indent=1):
        """Creates a DOT node with the given format information"""
        return '%s"%s" %s;\n' % ('\t' * indent, node, nodeFormat)

    @staticmethod
    def filledFormat(color=(0.0, 0.5, 1.0)):
        """Returns a string with DOT formatting information for a simple filled greenish-blue shape"""
        return '[style=filled, penwidth=4, color=\"%f %f %f\"]' % color

    @staticmethod
    def connection(srcNode, dstNode, connectionFormat='', indent=1):
        """Mark a connection between two DOT nodes"""
        return '%s"%s" -> "%s" %s;\n' % ('\t' * indent, srcNode, dstNode, connectionFormat)

    def __init__(self):
        """Initialize the allowed cluster color list and current color index."""
        self._clusterColors = [(i / 10.0, 0.5, 1.0) for i in range(10)]
        self._currentClusterIndex = 0

    def subgraphHeader(self, label):
        """Create a DOT subgraph with the given format information"""
        color = self._clusterColors[self._currentClusterIndex % len(self._clusterColors)]
        self._currentClusterIndex = (self._currentClusterIndex + 1)

        return '\tsubgraph cluster%d {\n\t\tnode [style=filled penwidth=4, color="%f %f %f"];\n\t\tlabel="%s";\n' % (self._currentClusterIndex, color[0], color[1], color[2], label)

    @staticmethod
    def subgraphFooter():
        """Close out the subgraph section"""
        return '\t}\n'

    @staticmethod
    def ellipseFormat():
        """Returns a string with DOT formatting information for a simple ellipse shape"""
        return '[shape=ellipse]'

    @staticmethod
    def colorFormat(color):
        """Returns a string with DOT formatting information for a colored shape"""
        return '[color="%f %f %f"]' % (color[0], color[1], color[2])
# ===========================================================================
# Copyright 2022 Autodesk, Inc. All rights reserved.
#
# Use of this software is subject to the terms of the Autodesk license
# agreement provided at the time of installation or download, or which
# otherwise accompanies this software in either electronic or hard copy form.
# ===========================================================================
