"""
Find information specific to the evaluation manager.
"""
import maya
maya.utils.loadStringResourcesForModule(__name__)

import re
import json
import maya.cmds as cmds
from  maya.debug.emModeManager import emModeManager
from .BaseAnalytic import BaseAnalytic, OPTION_DETAILS, OPTION_SUMMARY
from .decorators import addMethodDocs,addHelp,makeAnalytic

kAnalyticLabel = maya.stringTable['y_maya_analytics_analyticEvalManager.kAnalyticLabel' ]
kAnalyticDescriptionShort = maya.stringTable['y_maya_analytics_analyticEvalManager.kAnalyticDescriptionShort' ]

# Keywords for scheduling types in the dbpeek output
SCHEDULING_TYPES = ['Parallel', 'Serial', 'GloballySerial', 'Untrusted']
# Helper function to make the first character of a string lower case
MAKE_LOWER = lambda s: s[:1].lower() + s[1:] if s else ''

@addMethodDocs
@addHelp
@makeAnalytic(False)
class analyticEvalManager(BaseAnalytic):
    """
    The information regarding the evaluation graph and scheduling information
    for the current scene is output. The evaluation graph is updated before
    dumping the information so it is guaranteed to be current. If no options
    are selected the format shows the names of the nodes grouped by scheduling
    types as well as a list of the node clusters created for scheduling.

        "buildTime"      : GRAPH_BUILD_TIME_IN_MICROSECONDS
        "evaluationTime" : GRAPH_EVALUTION_TIME_IN_MICROSECONDS
        "parallel"       : [ LIST_OF_NODES_SCHEDULED_AS_PARALLEL ],
        "serial"         : [ LIST_OF_NODES_SCHEDULED_AS_SERIAL ],
        "globallySerial" : [ LIST_OF_NODES_SCHEDULED_AS_GLOBALLY_SERIAL ],
        "untrusted"      : [ LIST_OF_NODES_SCHEDULED_AS_UNTRUSTED ]
        "clusters"       : [ { CLUSTER_NAME : [ LIST_OF_NODES_IN_CLUSTER ] },
                             { CLUSTER_NAME : [ LIST_OF_NODES_IN_CLUSTER ] }
                             ...
                           ]
        The last is presented as an array of objects because the cluster names are not necessarily unique.

    Options Available

        summary = Show a count of the various scheduling and cluster types in the graph. Appends this section to the above.

                  "summary" : {
                      "parallel" : COUNT_OF_PARALLEL_NODES,
                      "serial" : COUNT_OF_SERIAL_NODES,
                      "globallySerial" : COUNT_OF_GLOBALLY_SERIAL_NODES,
                      "untrusted" : COUNT_OF_UNTRUSTED_NODES,
                      "clusters" : [ LIST_OF_NODE_COUNTS_PER_CLUSTER ],
                      "evaluationMaxWidth" : MAXIMUM_NUMBER_OF_CONCURRENT_NODES,
                      "evaluationMaxDepth" : MAXIMUM_PATH_LENGTH_FROM_ROOT_TO_LEAF
                  }

        details = Include all of the plug and connection information for each evaluation node. Instead of a list of node names
                  each node will be an object containing plug information:

                  "serial" : { "NODE_NAME" : { "inputPlugs"        : [ LIST_OF_INPUT_PLUGS_TO_DIRTY ],
                                               "outputPlugs"       : [ LIST_OF_OUTPUT_PLUGS_TO_DIRTY ],
                                               "affectsWorldPlugs" : [ LIST_OF_WORLD_AFFECTING_PLUGS_TO_DIRTY ]
                                             }
                             }

                  There will also be a separate section containing the list of all node connections as
                  [downstream,upstream] pairs. (Lists are used instead of tuples to make it JSON-friendly.)

                    "connections" : [ [NODE1, NODE2], [NODE1, NODE3]... ]

    Example of a graph with two nodes in one cluster dumped with the 'summary' option:

        "output" : {
            "summary" : {
                "parallel" : 1,
                "serial" : 1,
                "globallySerial" : 0,
                "untrusted" : 0,
                "clusters" : [1,1],
                "edges" : 1,
                "evaluationMaxWidth" : 1,
                "evaluationMaxDepth" : 1
            },
            "buildTime" : 12318,
            "evaluationTime" : 22418,
            "connections" : [ ["node1", "node2"] ],
            "parallel" : [ "node1" ],
            "serial" : [ "node2" ],
            "globallySerial" : [],
            "untrusted" : [],
            "clusters" : [
                { "pruneRootsEvaluator" : [ "node1" ] },
                { "cacheEvaluator" : [ "node2" ] }
            ]
        }

    The same graph with no options:

        output" : {
            "buildTime" : 12318,
            "evaluationTime" : 22418,
            "connections" : [ ["node1", "node2"] ],
            "parallel" : [ "node1" ],
            "serial" : [ "node2" ],
            "globallySerial" : [],
            "untrusted" : [],
            "clusters" : [
                { "pruneRootsEvaluator" : [ "node1" ] },
                { "cacheEvaluator" : [ "node2" ] }
            ]
        }

    The same graph with both 'summary' and 'details' options:

        "output" : {
            "summary" : {
                "parallel" : 1,
                "serial" : 1,
                "globallySerial" : 0,
                "untrusted" : 0,
                "clusters" : [1,1]
                "edges" : 1,
                "evaluationMaxWidth" : 1,
                "evaluationMaxDepth" : 1
            },
            "buildTime" : 12318,
            "evaluationTime" : 22418,
            "connections" : [ ["node1", "node2"] ],
            "parallel" : {
                "node1" : {
                    "input" : [ "node1.i" ],
                    "output" : [ "node1.wm", "node1.pm" ],
                    "affectsWorld" : [],
                    }
                },
            },
            "serial" : {
                "node2" : {
                    "input" : [],
                    "output" : [ "node2.o" ],
                    "affectsWorld" : [],
                }
            },
            "globallySerial" : {},
            "untrusted" : {},
            "clusters" : [
                { "pruneRootsEvaluator" : ["node1"] },
                { "cacheEvaluator" : ["node2"] }
            ]
        }
    """
    ANALYTIC_LABEL = kAnalyticLabel
    ANALYTIC_DESCRIPTION_SHORT = kAnalyticDescriptionShort

    #======================================================================
    def __graph_maximums(self, root_level):
        '''
        Compute the maximum width and depth of the subgraph described by the dictionary at root_level.
            KEY:   Nodes connected at this level
            VALUE: Dictionary of connections rooted at the KEY node
        :return: [MAXIMUM_WIDTH, MAXIMUM_DEPTH] from the given root
        '''
        max_width_so_far = len(root_level)
        max_depth_so_far = 0
        for (_, child_graph) in list(root_level.items()):
            if len(child_graph) > 0:
                (child_width, child_depth) = self.__graph_maximums(child_graph)
                if child_width > max_width_so_far:
                    max_width_so_far = child_width
                if child_depth > max_depth_so_far:
                    max_depth_so_far = child_depth

        # Add one to the depth so that this node is included as well
        return (max_width_so_far, max_depth_so_far+1)

    #======================================================================
    def __generate_scheduling_summary_data(self, raw_json):
        """
        Generates the summary data from the full JSON output.

        :param raw_json: Dictionary with key SCHEDULING_TYPES and value NODES_SCHEDULED_AS_THAT_TYPE
                         plus one key 'Clusters' which is a dictionary of {CLUSTER_NAME, LIST_OF_NODES_IN_THE_CLUSTER}
        :return:         Dictionary with the extracted scheduling summary information.
                             Key: SCHEDULING_TYPES     Value: Number of nodes scheduled with that type
                             Key: 'clusters'           Value: List of count of nodes in each cluster
                             Key: 'edges'              Value: Number of edges in the scheduling graph
                             Key: 'evaluationMaxWidth' Value: MAXIMUM_GRAPH_WIDTH
                             Key: 'evaluationMaxDepth' Value: MAXIMUM_GRAPH_DEPTH
        """
        scheduling_summary = {}
        try:
            edge_count = 0
            for _, edge_list in list(raw_json['edges'].items()):
                edge_count += len(edge_list)
            scheduling_summary['edges'] = edge_count

            scheduling_summary['clusters'] = [len(value) for (_, value) in list(raw_json['clusters'].items())]

            for scheduling_type in SCHEDULING_TYPES:
                scheduling_summary[MAKE_LOWER(scheduling_type)] = len(raw_json[scheduling_type])

            (max_width,max_depth) = self.__graph_maximums( raw_json['executionOrder'] )
            scheduling_summary['evaluationMaxWidth'] = max_width
            scheduling_summary['evaluationMaxDepth'] = max_depth

        except Exception as ex:
            self.error( 'Failed getting EM scheduling summary information ({})'.format(ex) )

        return scheduling_summary

    #======================================================================
    def __gather_detail_data(self):
        """
        Extracts the detailed data from the raw JSON output.

        :return: Dictionary containing a dictionary of {node:detailed_data}
        """
        node_details = {}
        try:
            plug_list = json.loads( cmds.dbpeek( operation='graph', all=True, evaluationGraph=True, argument=['plugs'] ) )['plugs']

            for (node, plug_types) in list(plug_list.items()):
                node_details[node] = {}
                for (plug_type, plug_type_list) in list(plug_types.items()):
                    if isinstance(plug_type_list, list):
                        node_details[node][plug_type] = plug_type_list[:]
                    else:
                        node_details[node][plug_type] = list(plug_type_list.keys())

        except Exception as ex:
            self.error( 'Failed getting EM detailed information ({})'.format(ex) )

        return node_details

    #======================================================================
    def __get_event_timing(self, event):
        """
        Use the profiler data to extract the timing taken by a named event.
        If more than one event of the given name exists only the first one
        will be used.

        :param event: Profiler event name for which to extract timing
        :return:      The amount of time, in microseconds, taken by the event
        """
        self.debug( 'Getting event timing for {}'.format(event) )
        event_time = 0
        try:
            re_event = re.compile( r'^(@[0-9]+)\s+=\s+{}$'.format(event) )
            tmp_dir = cmds.internalVar(userTmpDir=True)
            from os import path as os_path
            tmp_file = os_path.join( tmp_dir, '__PROFILER__.txt' )
            cmds.profiler( output=tmp_file )
            profiler_data = open( tmp_file, 'r' ).readlines()
            from os import remove as os_remove
            os_remove( tmp_file )

            found_event = None
            for line in profiler_data:
                if found_event is not None:
                    fields = line.split('\t')
                    if len(fields) > 4 and fields[1] == found_event:
                        self.debug( 'Found the timing' )
                        event_time = int(fields[4])
                        # Reset to keep looking - use the last found match as the timing
                        found_event = None
                else:
                    match = re_event.match(line)
                    if match:
                        self.debug( 'Found the event' )
                        found_event = match.group(1)
        except Exception as ex:
            self.error( 'Failed to get timing of event {}: {}'.format(event, ex) )

        return event_time

    #======================================================================
    def __extract_connections(self):
        '''
        Extract the list of connections in the current evaluation graph
        :return: List of connections in the graph as pairs of nodes (upstream, downstream)
        '''
        connection_list = []
        try:
            connection_json = json.loads( cmds.dbpeek( operation='graph', all=True, evaluationGraph=True, argument='connections' ) )['connections']
            for (node, connections) in list(connection_json.items()):
                downstream_connections = connections['downstream']
                for downstream_connection in downstream_connections:
                    for downstream_node in list(downstream_connection.values()):
                        connection_list.append( [node, downstream_node] )
        except Exception as ex:
            self.warning( 'Connection collection failed ({})'.format(ex) )

        return connection_list

    #======================================================================
    def run(self):
        """
        Run the analytic on the current scene.
        :return: a JSON structure as described in the class doc
        """
        node_data = {}

        try:
            with emModeManager() as em_manager:

                # Rebuild the graph in parallel mode, then extract the schedulingGraph event
                # timing from it, which is the root level timing event for graph rebuilding.
                # (The rebuild also counts invalidation and redraw time so that can't be used as-is.)
                em_manager.setMode( 'emp' )

                self.debug( 'Getting profiler information' )
                now = cmds.currentTime( query=True )
                cmds.profiler( sampling=True )
                em_manager.rebuild( include_scheduling=True )
                cmds.refresh( force=True )
                cmds.currentTime( now )
                cmds.profiler( sampling=False )
                node_data['buildTime'] = self.__get_event_timing( 'EvaluationGraphConstruction' )
                node_data['evaluationTime'] = self.__get_event_timing( 'SetCurrentTime' )
                self.debug( 'Got the sample times of {} and {}'.format( node_data['buildTime'], node_data['evaluationTime'] ) )

                # Gather up the connections
                connections = self.__extract_connections()
                node_data['connections'] = connections

                # In verbose mode the nodes will include their dirty plugs
                detailed_info = self.__gather_detail_data() if self.option(OPTION_DETAILS) else {}

                # Get the scheduling information for extraction of the rest of the information
                try:
                    graph_data = cmds.dbpeek( operation='graph', all=True, evaluationGraph=True, argument=['scheduling','verbose'] )
                    em_json = json.loads( graph_data )['scheduling']
                except Exception as ex:
                    self.warning( 'Error parsing the dbpeek output ({})'.format(ex) )
                    raise ex

                # Transfer simple data over to the output
                node_data['edges'] = em_json['edges']
                node_data['execution'] = em_json['executionOrder']
                node_data['clusters'] = em_json['clusters']

                # Insert detailed information into the scheduling information as it is transferred over to the output
                try:
                    for scheduling_type in SCHEDULING_TYPES:
                        scheduling_list = em_json[scheduling_type]
                        scheduling_name = MAKE_LOWER(scheduling_type)

                        # The simplest output will just have the nodes of each type in a list.
                        if not self.option(OPTION_SUMMARY) and not self.option(OPTION_DETAILS):
                            node_data[scheduling_name] = scheduling_list
                            continue

                        node_data[scheduling_name] = {}
                        for node in scheduling_list:
                            node_info = {}

                            # Add in the detailed information if requested
                            if node in detailed_info:
                                node_info.update( detailed_info[node] )

                            # Attach the node data to its name
                            node_data[scheduling_name][self._node_name(node)] = node_info

                except Exception as ex:
                    # There may be a formatting problem if scheduling types
                    # are not found since they will be dumped even if empty.
                    self.warning( 'Node information not available for type {} ({})'.format(scheduling_type, ex) )

                # Generate the summary information if requested
                if self.option(OPTION_SUMMARY):
                    summary_info = self.__generate_scheduling_summary_data(em_json)
                    summary_info['connections'] = len(connections)
                    node_data['summary'] = summary_info

        except Exception as ex:
            # If there is no animation there will be no evaluation graph
            self.warning( 'No Evaluation Manager information available ({})'.format(ex) )

        return node_data
# ===========================================================================
# Copyright 2022 Autodesk, Inc. All rights reserved.
#
# Use of this software is subject to the terms of the Autodesk license
# agreement provided at the time of installation or download, or which
# otherwise accompanies this software in either electronic or hard copy form.
# ===========================================================================
