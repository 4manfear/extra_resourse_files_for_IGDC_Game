"""
Helper class that maintains the cache evaluator mode information.
Manages the cache evaluator-specific data, the common data is
managed by the base class.

The object is set up to use the Python "with" syntax as follows:

    from maya.plugin.evaluator.CacheEvaluatorManager import CacheEvaluatorManager
    with CacheEvaluatorManager() as mgr:
        mgr.cache_mode = some_mode

That will ensure the original states are all restored. There's no other
reliable way to do it in Python. If you need different syntax you can
manually call the method to complete the sequence:

    mgr = CacheEvaluatorManager()
    mgr.save_state()
    mgr.cache_mode = some_mode
    mgr.restore_state()

If you attempt to read or write a state value and the plug-in is not loaded
then a ValueError will be raised with a plug-in not loaded message.
"""
import maya
maya.utils.loadStringResourcesForModule(__name__)

import json
import warnings
import maya.cmds as cmds
from maya.debug.TODO import TODO
from maya.debug.EvaluatorManager import EvaluatorManager
from maya.debug.PlaybackManager import PlaybackManager
from maya.app.prefs.OptionVar import OptionVar
from maya.plugin.evaluator.cache_optionvar_states import CachePreferenceHud, CachePreferenceResourceGuard, CachePreferenceMemoryThreshold, CachePreferenceDiscardFramesOutOfRange
from maya.plugin.evaluator.cache_debugging import CP_DBG

__all__ = [ r'CacheEvaluatorManager'
          , r'supported_shape_types_filter'
          , r'standard_modes'
          , r'CACHE_STANDARD_MODE_VP2_HW'
          , r'CACHE_STANDARD_MODE_VP2_SW'
          , r'CACHE_STANDARD_MODE_EVAL'
          , r'CACHE_STANDARD_MODE_EVAL_SHAPES'
          , r'CACHE_STANDARD_MODE_VP2_HW_NO_FALLBACK'
          , r'CACHE_STANDARD_MODE_VP2_SW_NO_FALLBACK'
          , r'KEY_CACHE_MODE'
          , r'KEY_ASYNCHRONOUS'
          , r'KEY_SAFE_MODE'
          , r'KEY_RESOURCE_GUARD'
          , r'KEY_MEMORY_THRESHOLD'
          , r'KEY_PREVENT_FRAME_SKIPPING'
          , r'KEY_DISCARD_FRAMES_OUT_OF_RANGE'
          , r'KEY_DYNAMICS_SUPPORT_ENABLED'
          , r'KEY_DYNAMICS_ASYNC_REFRESH'
          , r'CACHE_PLUGIN_NAME'
          , r'CacheLayers'
          ]

# Name of the plug-in containing the cache evaluator
CACHE_PLUGIN_NAME = r'cacheEvaluator'

# Name of the evaluator
EVALUATOR_NAME = r'cache'

# Keys for the dictionary containing configuration information
KEY_CACHE_MODE                  = r'cache_mode'
KEY_ASYNCHRONOUS                = r'asynchronous'
KEY_FILL_MODE                   = r'fill_mode'
KEY_FILL_ORDER                  = r'fill_order'
KEY_HUD                         = r'hud'
KEY_FLUSH_SYNC                  = r'flush_sync'
KEY_SAFE_MODE                   = r'safe_mode'
KEY_RESOURCE_GUARD              = r'resource_guard'
KEY_MEMORY_THRESHOLD            = r'memory_threshold'
KEY_PREVENT_FRAME_SKIPPING      = r'prevent_frame_skipping'
KEY_DISCARD_FRAMES_OUT_OF_RANGE = r'discard_frames_out_of_range'
KEY_DYNAMICS_SUPPORT_ENABLED    = r'dynamics_support_enabled'
KEY_DYNAMICS_ASYNC_REFRESH      = r'dynamics_async_refresh'
KEY_LAYERED_EVALUATION_ENABLED  = r'layered_evaluation_enabled'
KEY_HYBRID_CACHE_MODE           = r'hybrid_cache_mode'

ASYNC_DEPRECATED = maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kAsyncDeprecated' ]

#======================================================================
def supported_shape_types_filter():
    ''':return: List of node types supporting caching'''
    
    return r'+mesh,+nurbsCurve,+bezierCurve,+nurbsSurface,+subdiv,+lattice,+baseLattice,+cMuscleDebug,+cMuscleDirection,+cMuscleDisplace,+cMuscleDisplay,+cMuscleFalloff,+cMuscleKeepOut,+cMuscleObject,+cMuscleSmartCollide,+cMuscleSpline,+cMuscleSurfAttach,-THlocatorShape,+locator,+light,+camera,+imagePlane,+clusterHandle,+deformFunc,+hwShader,+pfxGeometry,+follicle'

#======================================================================

#
# Default modes
#
KEY_NEW_ACTION       = r'newAction'
KEY_NEW_ACTION_PARAM = r'newActionParam'
KEY_NEW_FILTER       = r'newFilter'
KEY_NEW_FILTER_PARAM = r'newFilterParam'
KEY_NEW_RULE         = r'newRule'

# VP2 Hardware Cache
CACHE_STANDARD_MODE_VP2_HW = [ { KEY_NEW_FILTER       : r'evaluationCacheNodes'
                               , KEY_NEW_ACTION       : r'enableEvaluationCache' }
                             , { KEY_NEW_FILTER       : r'vp2CacheNodes'
                               , KEY_NEW_ACTION       : r'enableVP2Cache'
                               , KEY_NEW_ACTION_PARAM : r'useHardware=1' }
                             , { KEY_NEW_FILTER       : r'hybridCache'
                               , KEY_NEW_FILTER_PARAM : r'mode=usePreference'
                               , KEY_NEW_ACTION       : r'delegateEvaluation' }
                             , { KEY_NEW_RULE         : r'customEvaluators' } ]
# VP2 Software Cache
CACHE_STANDARD_MODE_VP2_SW = [ { KEY_NEW_FILTER       : r'evaluationCacheNodes'
                               , KEY_NEW_ACTION       : r'enableEvaluationCache' }
                             , { KEY_NEW_FILTER       : r'vp2CacheNodes'
                               , KEY_NEW_ACTION       : r'enableVP2Cache'
                               , KEY_NEW_ACTION_PARAM : r'useHardware=0' }
                             , { KEY_NEW_FILTER       : r'hybridCache'
                               , KEY_NEW_FILTER_PARAM : r'mode=usePreference'
                               , KEY_NEW_ACTION       : r'delegateEvaluation' }
                             , { KEY_NEW_RULE         : r'customEvaluators' } ]
# Evaluation Cache
CACHE_STANDARD_MODE_EVAL   = [ { KEY_NEW_FILTER       : r'evaluationCacheNodes'
                               , KEY_NEW_ACTION       : r'enableEvaluationCache' }
                             , { KEY_NEW_FILTER       : r'hybridCache'
                               , KEY_NEW_FILTER_PARAM : r'mode=usePreference'
                               , KEY_NEW_ACTION       : r'delegateEvaluation' }
                             , { KEY_NEW_RULE         : r'customEvaluators' } ]

#
# Debugging modes
#

# Evaluation Cache for shapes only, no transform except the ones directly parenting shapes.
CACHE_STANDARD_MODE_EVAL_SHAPES = [ { KEY_NEW_FILTER       : r'nodeTypes'
                                    , KEY_NEW_FILTER_PARAM : r'types=' + supported_shape_types_filter()
                                    , KEY_NEW_ACTION       : r'enableEvaluationCache' }
                                  , { KEY_NEW_FILTER       : r'downstreamNodeTypes'
                                    , KEY_NEW_FILTER_PARAM : r'types=+dagNode downstreamTypes=' + supported_shape_types_filter()
                                    , KEY_NEW_ACTION       : r'enableEvaluationCache' }
                                  , { KEY_NEW_RULE         : r'customEvaluators' } ]
# VP2 Hardware Cache (Without Fallback)
CACHE_STANDARD_MODE_VP2_HW_NO_FALLBACK = [ { KEY_NEW_FILTER       : r'evaluationCacheNodes'
                                           , KEY_NEW_ACTION       : r'enableEvaluationCache' }
                                         , { KEY_NEW_FILTER       : r'vp2CacheNodes'
                                           , KEY_NEW_ACTION       : r'enableVP2Cache'
                                           , KEY_NEW_ACTION_PARAM : r'useHardware=1 fallback=0' }
                                         , { KEY_NEW_RULE         : r'customEvaluators' } ]
# VP2 Software Cache (Without Fallback)
CACHE_STANDARD_MODE_VP2_SW_NO_FALLBACK = [ { KEY_NEW_FILTER       : r'evaluationCacheNodes'
                                           , KEY_NEW_ACTION       : r'enableEvaluationCache' }
                                         , { KEY_NEW_FILTER       : r'vp2CacheNodes'
                                           , KEY_NEW_ACTION       : r'enableVP2Cache'
                                           , KEY_NEW_ACTION_PARAM : r'useHardware=0 fallback=0' }
                                         , { KEY_NEW_RULE         : r'customEvaluators' } ]

# Named bit masks for common cache layers
# This class should be derived from `enum.IntEnum`, but we do not have python 3
class CacheLayers:
    # Bits mask for basic cache layer
    BASIC    = 0b01
    # Bits mask for dynamics cache layer
    DYNAMICS = 0b10
    # Bits mask for all the cache layers
    ALL      = BASIC | DYNAMICS

#======================================================================
def standard_modes():
    ''':return: List of (name,parameter_list) state setup values for the current standard set of usable modes'''
    return [
        (r'VP2_HW',      CACHE_STANDARD_MODE_VP2_HW)
    ,   (r'VP2_SW',      CACHE_STANDARD_MODE_VP2_SW)
    ,   (r'EVAL',        CACHE_STANDARD_MODE_EVAL)
    ,   (r'EVAL_SHAPES', CACHE_STANDARD_MODE_EVAL_SHAPES)
        ]

#======================================================================
def non_vp2_viewport_exists():
    '''
    Return True if a viewport that does not use Viewport 2.0 exists.
    '''
    panels = cmds.getPanel(visiblePanels=True)
    if panels is None:
        return False

    modelEditors = [panel for panel in panels if cmds.modelEditor(panel, query=True, exists=True)]
    for panel in modelEditors:
        rendererName = cmds.modelEditor(panel, query=True, rendererName=True)
        if not rendererName == r'vp2Renderer':
            return True
    return False

#======================================================================
class CacheEvaluatorManager(EvaluatorManager):
    '''
    Class for managing the cache evaluator state in a 'with' format. Remembers
    and restores the caching mode and parameters.
    '''
    #----------------------------------------------------------------------
    class CacheEvaluatorState(EvaluatorManager.EvaluatorState):
        '''
        State information of the evaluator
            :member fill_mode:                   When to fill the cache
            :member fill_order:                  The order for background cache filling
            :member hud:                         Whether or not the caching information is displayed in the heads-up display
            :member flush_sync:                  Use synchronous flush if true or asynchronus flush if false
            :member cache_mode:                  Array of rules description for the current mode
            :member safe_mode:                   Is the cache evaluation currently in safe mode?
            :member resource_guard:              Is the memory resource safeguard enabled?
            :member memory_threshold:            Maximum percentage of memory to occupy before shutting down caching
            :member prevent_frame_skipping:      Should frames be skipped when filling in frame-rate locked modes?
            :member discard_frames_out_of_range: Should cached frames be released when they are not in playback range
            :member dynamics_support_enabled:    Should cached playback work with Dynamics nodes
            :member dynamics_async_refresh:      Should foreground content be updated during background dynamics simulation
            :member layered_evaluation_enabled:  Should Dynamics content cache be fill in a second run
            :member hybrid_cache_mode:           When to use GPU deformation instead of caching
        '''
        def __init__(self):
            '''Set the state information to some default values'''
            super( CacheEvaluatorManager.CacheEvaluatorState, self ).__init__()
            self.fill_mode                   = None
            self.fill_order                  = None
            self.hud                         = None
            self.flush_sync                  = None
            self.cache_mode                  = None
            self.safe_mode                   = None
            self.resource_guard              = None
            self.memory_threshold            = None
            self.prevent_frame_skipping      = None
            self.discard_frames_out_of_range = None
            self.dynamics_support_enabled    = None
            self.dynamics_async_refresh      = None
            self.layered_evaluation_enabled  = None
            self.hybrid_cache_mode           = None

    #----------------------------------------------------------------------
    def save_state(self):
        '''
        Remember the current state of all EM related parameters so that they
        can be restored on exit.
        '''
        
        self.state = CacheEvaluatorManager.CacheEvaluatorState()
        super( CacheEvaluatorManager, self ).save_state()

        # These values will be remembered even if the plug-in is not loaded because they
        # are stored as optionVars.
        self.state.resource_guard = self.resource_guard
        self.state.memory_threshold = self.memory_threshold

        
        # If the plug-in is not loaded there's no data to collect
        if not self.state.plugin_loaded:
            return

        #----------------------------------------
        # Cache-specific parameters
        self.state.cache_mode                  = self.cache_mode
        self.state.fill_mode                   = self.fill_mode
        self.state.fill_order                  = self.fill_order
        self.state.hud                         = self.hud
        self.state.flush_sync                  = self.flush_sync
        self.state.safe_mode                   = self.safe_mode
        self.state.resource_guard              = self.resource_guard
        self.state.memory_threshold            = self.memory_threshold
        self.state.prevent_frame_skipping      = self.prevent_frame_skipping
        self.state.discard_frames_out_of_range = self.discard_frames_out_of_range
        self.state.dynamics_support_enabled    = self.dynamics_support_enabled
        self.state.dynamics_async_refresh      = self.dynamics_async_refresh
        self.state.layered_evaluation_enabled  = self.layered_evaluation_enabled
        self.state.hybrid_cache_mode           = self.hybrid_cache_mode

    #----------------------------------------------------------------------
    def __init__(self):
        '''
        __enter__ is defined in the parent class
        '''
        self.state = None
        super( CacheEvaluatorManager, self ).__init__( EVALUATOR_NAME, CACHE_PLUGIN_NAME )

        
        # This may not be used but it will be available for reference
        self.save_state()

    #----------------------------------------------------------------------
    def __exit__(self,event_type,value,traceback): # pylint: disable=redefined-builtin
        '''Ensure the state is restored if this object goes out of scope'''

        
        
        
        from traceback import format_list, extract_tb
        

        self.restore_state()

    #----------------------------------------------------------------------
    def check_plugin(self):
        '''
        Confirm that the plug-in is loaded.
        :raise OptionVar.StateError: The plug-in is not currently loaded
        '''
        if not self.plugin_loaded:
            raise OptionVar.StateError( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kPluginNotLoaded' ].format( EVALUATOR_NAME ) )

    #----------------------------------------------------------------------
    @staticmethod
    def flush_cache():
        '''Flush the current cache, if any'''
        try:
            cmds.cacheEvaluator(flushCache=r'destroy')
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            pass

    #----------------------------------------------------------------------
    @staticmethod
    def flush_cache_range(min_time, max_time, flush_inside_range):
        '''
        Flush a portion of the current cache, if any
        :param min_time: Start of the time range for flushing
        :param max_time: End of the time range for flushing
        :param flush_inside_range: If True then flush anything in [min_time,max_time],
            otherwise flush anything outside that range (i.e. [-inf,min_time) U (max_time, inf])
        '''
        try:
            cmds.cacheEvaluator(flushCacheRange=[(min_time, max_time), flush_inside_range])
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            pass

    #----------------------------------------------------------------------
    @staticmethod
    def wait_for_cache(max_time=2.0):
        '''
        Wait for any pending cache fills.
        :param max_time: Maximum number of seconds to wait for the cache to fill (0 = just check without waiting)
        :return: True if the cache is ready after waiting
        '''
        cache_is_ready = False
        try:
            cmds.flushIdleQueue()   # In case a background evaluation has been queued up but not started
            cache_is_ready = cmds.cacheEvaluator(waitForCache=max_time)
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            cache_is_ready = True
        return cache_is_ready

    #----------------------------------------------------------------------
    @staticmethod
    def invalidate_cache():
        '''Invalidate the current cache, if any'''
        try:
            with PlaybackManager() as play_mgr:
                cmds.cacheEvaluator( cacheInvalidate=(r'{0}'.format(play_mgr.minTime), r'{0}'.format(play_mgr.maxTime)) )
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            pass

    #----------------------------------------------------------------------
    def rebuild_cache(self, wait_for_rebuild):
        '''
        Rebuild the current cache, if available
        :param wait_for_rebuild: If true then do not return until the cache has rebuilt
        :return: True if the cache was rebuilt and is available
        '''
        cache_available = False
        try:
            if not self.enabled:
                cmds.warning( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kNoRebuildWhenDisabled'  ] )
            elif self.safe_mode_triggered:
                cmds.warning( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kNoRebuildInSafeMode'  ] )
            else:
                # If in safe mode or rebuilding synchronously a playback has to run to rebuild
                # the cache, otherwise just a time setting is needed and optional wait
                if self.fill_mode != r'syncOnly':
                    cmds.currentTime( cmds.currentTime(query=True) )
                    wait_time = 999 if wait_for_rebuild else 0
                    cache_available = cmds.cacheEvaluator( waitForCache=wait_time )
                elif not wait_for_rebuild:
                    cmds.warning( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kHaveToWaitInSyncMode'  ] )
                else:
                    play_mgr = PlaybackManager()
                    play_mgr.play_all()
                    cache_available = cmds.cacheEvaluator( waitForCache=0 )
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            pass

        return cache_available

    #----------------------------------------------------------------------
    def cached_nodes(self, potential_nodes):
        '''
        Find the currently cached nodes. This method doesn't care which cache the values are in
        only that at least one cache has data for a given node.
        :param potential_nodes: Set of nodes to check for caching. If None then use the list of
                                all evaluation graph nodes instead.
        :return: Set of nodes with data in a cache
        '''
        cached_nodes = set()
        try:
            caching_points = cmds.cacheEvaluator( query=True, cachingPoints=True )
            cached_nodes = set(caching_points) & (potential_nodes or set())

        except (ValueError, KeyError) as ex:
            # Extraction may have failed when the graph doesn't exist or when the evaluator
            # command failed.
            cmds.warning( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kExtractFailure' ].format(ex) )

        return cached_nodes

    #----------------------------------------------------------------------
    def as_json(self):
        '''Display mechanism to retrieve evaluator information in a format conducive to JSON formatting'''

        info = super( CacheEvaluatorManager, self ).as_json()

        if not self.plugin_loaded:
            return {}

        info.update( { KEY_CACHE_MODE                  : self.cache_mode
                     , KEY_FILL_MODE                   : self.fill_mode
                     , KEY_FILL_ORDER                  : self.fill_order
                     , KEY_HUD                         : self.hud
                     , KEY_FLUSH_SYNC                  : self.flush_sync
                     , KEY_SAFE_MODE                   : self.safe_mode
                     , KEY_RESOURCE_GUARD              : self.resource_guard
                     , KEY_MEMORY_THRESHOLD            : self.memory_threshold
                     , KEY_PREVENT_FRAME_SKIPPING      : self.prevent_frame_skipping
                     , KEY_DISCARD_FRAMES_OUT_OF_RANGE : self.discard_frames_out_of_range
                     , KEY_DYNAMICS_SUPPORT_ENABLED    : self.dynamics_support_enabled
                     , KEY_DYNAMICS_ASYNC_REFRESH      : self.dynamics_async_refresh
                     , KEY_HYBRID_CACHE_MODE           : self.hybrid_cache_mode
                     } )

        return info

    #----------------------------------------------------------------------
    def set_state(self, new_state):
        '''
        Define the cache evaluator state parameters.
        :param new_state: State information in the format provided by as_json
                          Only key values specified will change. Others retain
                          their current values (*not* default values).
        '''
        if not self.plugin_loaded:
            return

        super( CacheEvaluatorManager, self ).set_state( new_state )

        

        for key, value in list(new_state.items()):
            if key == KEY_CACHE_MODE:
                self.cache_mode = value
            elif key == KEY_ASYNCHRONOUS:
                self.asynchronous = value
            elif key == KEY_FILL_MODE:
                self.fill_mode = value
            elif key == KEY_FILL_ORDER:
                self.fill_order = value
            elif key == KEY_HUD:
                self.hud = value
            elif key == KEY_FLUSH_SYNC:
                self.flush_sync = value
            elif key == KEY_SAFE_MODE:
                self.safe_mode = value
            elif key == KEY_RESOURCE_GUARD:
                self.resource_guard = value
            elif key == KEY_MEMORY_THRESHOLD:
                self.memory_threshold = value
            elif key == KEY_PREVENT_FRAME_SKIPPING:
                self.prevent_frame_skipping = value
            elif key == KEY_DISCARD_FRAMES_OUT_OF_RANGE:
                self.discard_frames_out_of_range = value
            elif key == KEY_DYNAMICS_SUPPORT_ENABLED:
                self.dynamics_support_enabled = value
            elif key == KEY_DYNAMICS_ASYNC_REFRESH:
                self.dynamics_async_refresh = value
            elif key == KEY_LAYERED_EVALUATION_ENABLED:
                self.layered_evaluation_enabled = value
            elif key == KEY_HYBRID_CACHE_MODE:
                self.hybrid_cache_mode = value
            # No else case because the base class has its own keys

    #----------------------------------------------------------------------
    def restore_state(self):
        '''
        Restore the cache evaluator to its original mode prior to creation of
        this object. Using the "with" syntax this will be called automatically.
        You only need to call explicitly when you instantiate the mode manager
        as an object.
        '''
        

        super( CacheEvaluatorManager, self ).restore_state()

        # Restore the evaluator state. If the state wasn't taken from a loaded plug-in then it
        # wasn't valid.
        if self.state.plugin_loaded:
            self.plugin_loaded = True # Force loading the plug-in so that state can be restored
            self.cache_mode                  = self.state.cache_mode
            self.fill_mode                   = self.state.fill_mode
            self.fill_order                  = self.state.fill_order
            self.hud                         = self.state.hud
            self.flush_sync                  = self.state.flush_sync
            self.safe_mode                   = self.state.safe_mode
            self.resource_guard              = self.state.resource_guard
            self.memory_threshold            = self.state.memory_threshold
            self.prevent_frame_skipping      = self.state.prevent_frame_skipping
            self.discard_frames_out_of_range = self.state.discard_frames_out_of_range
            self.dynamics_support_enabled    = self.state.dynamics_support_enabled
            self.dynamics_async_refresh      = self.state.dynamics_async_refresh
            self.layered_evaluation_enabled  = self.state.layered_evaluation_enabled
            self.hybrid_cache_mode           = self.state.hybrid_cache_mode

        # These are optionVars and do not rely on the plug-in
        self.resource_guard = self.state.resource_guard
        self.memory_threshold = self.state.memory_threshold

        # Load or unload the plug-in, as it was when state was saved
        self.plugin_loaded = self.state.plugin_loaded

    #----------------------------------------------------------------------
    #
    # Use properties to make it easier to access the evaluator information
    #
    @property
    def fill_mode(self):
        ''' :return: the evaluator's current fill mode, decide when the cache will be filled.  '''
        self.check_plugin()
        return cmds.cacheEvaluator(query=True, cacheFillMode=True)

    @fill_mode.setter
    def fill_mode(self, new_value):
        '''
        Give the evaluator a new fill mode
        :param new_value: new value for fill mode, must be one of ['asyncOnly', 'syncOnly', 'syncAsync']
        '''
        self.check_plugin()
        
        try:
            cmds.cacheEvaluator(cacheFillMode = new_value)
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedFillMode'].format(ex) )

    #----------------------------------------------------------------------
    @property
    def enabled(self):
        '''Return the evaluator's enabled state'''
        return super( CacheEvaluatorManager, self).enabled

    @enabled.setter
    def enabled(self, new_value):
        '''
        Change the enabled state of the evaluator, and flush the cache if disabling
        :param new_value: new value for enabled, True or False
        '''
        self.check_plugin()
        

        if self.enabled == new_value:
            return

        try:
            super( CacheEvaluatorManager, self.__class__ ).enabled.fset(self, new_value)
            # If the cache evaluator was disabled then also flush the cache since that data
            # will no longer be used (and may be needed by the rest of the system).
            if not new_value:
                self.flush_cache()
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedEnabled' ].format(ex) )

    #----------------------------------------------------------------------
    @property
    def asynchronous(self):
        '''
        :return: the evaluator's asynchronous state.
        The conversions are needed because the command returns the true/false value as a string.
        '''
        warnings.warn( ASYNC_DEPRECATED, DeprecationWarning)
        mode = self.fill_mode
        return mode == r'asyncOnly' or mode == r'syncAsync'

    @asynchronous.setter
    def asynchronous(self, new_value):
        '''
        Give the evaluator a new asynchronous state
        :param new_value: New asynchronous state for the evaluator
        '''
        warnings.warn( ASYNC_DEPRECATED, DeprecationWarning)
        if new_value:
            mode = r'syncAsync'
        else:
            mode = r'syncOnly'
        self.fill_mode = mode

    #----------------------------------------------------------------------
    @property
    def fill_order(self):
        ''' :return: the evaluator's background fill order '''
        self.check_plugin()
        return cmds.cacheEvaluator(query=True, cacheFillOrder=True)

    @fill_order.setter
    def fill_order(self, new_value):
        '''
        Give the evaluator a new background fill order
        :param new_value: new value for fill order, must be one of ['forward', 'backward', 'bidirectional', 'forwardFromBegin']
        '''
        self.check_plugin()
        
        try:
            cmds.cacheEvaluator( cacheFillOrder = new_value )
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedFillOrder' ].format(ex) )

    #----------------------------------------------------------------------
    @property
    def flush_sync(self):
        ''' :return: the evaluator's flush synchronization mode '''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator(query=True, flushCacheSync=True)))

    @flush_sync.setter
    def flush_sync(self, new_value):
        '''
        Give the evaluator a new flush synchronization mode
        :param new_value: new value for synchronization mode, True for synchronous flush, False for asynchronous flush
        '''
        

        try:
            cmds.cacheEvaluator( flushCacheSync = bool(int(new_value)) )
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailFlushSync' ].format(ex) )

    #----------------------------------------
    @property
    def cache_mode(self):
        ''':return: the list of rules descriptions being used for the current caching mode'''
        self.check_plugin()
        try:
            caching_mode = json.loads( cmds.cacheEvaluator( query=True, creationParameters=True ) )
        except RuntimeError:
            caching_mode = []
        from sys import version_info as sys_version_info
        if sys_version_info[0] >= 3:
            return [{key: value for key, value in list(rule.items())} for rule in caching_mode]

        # json.loads creates unicode strings as keys which cannot be used as argument names when
        # unpacking the dictionary, which prevents doing something like cmds.cacheEvaluator(**rule)
        # so, for Python 2.7 we convert them to ascii.
        return [{key.encode(r'ascii'): value for key, value in list(rule.items())} for rule in caching_mode]

    @cache_mode.setter
    def cache_mode(self, new_value):
        '''
        Give the evaluator a new set of cache configuration rules to use as the current mode
        :param new_value: List of rules descriptions to use for caching mode
        '''
        self.check_plugin()
        current_values = self.cache_mode
        if current_values == new_value:
            return

        
        try:
            cmds.cacheEvaluator( resetRules=True )
            for rule in new_value:
                cmds.cacheEvaluator( **rule )

            # Need a warning if the caching mode was set to a VP2 mode but one or more viewports
            # do not use the VP2 renderer.
            vp2_caching = (new_value == CACHE_STANDARD_MODE_VP2_SW or new_value == CACHE_STANDARD_MODE_VP2_HW)
            if vp2_caching and non_vp2_viewport_exists():
                cmds.warning(maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kNonVP2UsedInVP2Caching' ])

        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedCacheMode' ].format(ex) )

    #----------------------------------------
    @property
    def prevent_frame_skipping(self):
        ''':return: the evaluator's prevent-frame-skipping state value'''
        self.check_plugin()
        return True if int(cmds.cacheEvaluator(query=True, preventFrameSkip=True)) else False

    @prevent_frame_skipping.setter
    def prevent_frame_skipping(self, new_value):
        '''
        Set the prevent-frame-skipping state for the evaluator.
        :param new_value: New prevent-frame-skipping state for the evaluator
        '''
        self.check_plugin()
        if self.prevent_frame_skipping == new_value:
            return

        
        try:
            cmds.cacheEvaluator(preventFrameSkip=new_value)
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedPreventSkip' ].format(ex) )

   #----------------------------------------
    @property
    def dynamics_support_enabled(self):
        ''':return: the evaluator's dynamics-support-enabled state value'''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator(query=True, dynamicsSupportEnabled=True)))

    @dynamics_support_enabled.setter
    def dynamics_support_enabled(self, new_value):
        '''
        Set the dynamics-support-enabled state for the evaluator.
        :param new_value: New dynamics-support-enabled state for the evaluator
        '''
        self.check_plugin()
        if self.dynamics_support_enabled == new_value:
            return

        
        try:
            cmds.cacheEvaluator(dynamicsSupportEnabled=new_value)
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedDynamicsSupport' ].format(ex) )

    #----------------------------------------
    @property
    def dynamics_support_active(self):
        ''':return: if there are dynamics nodes presented in the scene, and handled by cache evaluator.'''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator(query=True, dynamicsSupportActive=True)))

    #----------------------------------------
    @property
    def dynamics_async_refresh(self):
        ''':return: the evaluator's dynamics-async-refresh state value'''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator(query=True, dynamicsAsyncRefresh=True)))

    #----------------------------------------
    @dynamics_async_refresh.setter
    def dynamics_async_refresh(self, new_value):
        '''
        Set the dynamics-async-refresh state for the evaluator.
        :param new_value: New dynamics-async-refresh state for the evaluator
        '''
        self.check_plugin()
        if self.dynamics_async_refresh == new_value:
            return

        
        try:
            cmds.cacheEvaluator(dynamicsAsyncRefresh=new_value)
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedDynamicsAsync' ].format(ex) )

    @property
    def layered_evaluation_enabled(self):
        ''':return: the evaluator's layered-evaluation-enabled state value.'''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator(query=True, layeredEvaluationEnabled=True)))

    @layered_evaluation_enabled.setter
    def layered_evaluation_enabled(self, new_value):
        '''
        Set the layered-evaluation-enabled state for the evaluator.
        :param new_value: New layered-evaluation-enabled state for the evaluator
        '''
        self.check_plugin()
        if self.layered_evaluation_enabled == new_value:
            return

        
        try:
            cmds.cacheEvaluator(layeredEvaluationEnabled=new_value)
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedLayeredEvaluation' ].format(ex) )

    @property
    def layered_evaluation_active(self):
        ''':return: if there are layered evaluation nodes presented in the scene, and handled by cache evaluator.'''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator(query=True, layeredEvaluationActive=True)))

    @property
    def layered_evaluation_cached_nodes(self):
        '''
        Find the currently cached nodes because of layered evaluation.
        :return: Set of nodes that forced to being cached for layered evaluation.
        '''
        cached_nodes = {}
        try:
            caching_points = cmds.cacheEvaluator( query=True, layeredEvaluationCachingPoints=True )
            cached_nodes = set(caching_points)

        except (ValueError, KeyError) as ex:
            # Extraction may have failed when the graph doesn't exist or when the evaluator
            # command failed.
            cmds.warning( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kLayeredExtractFail' ].format(ex) )

        return cached_nodes

    #----------------------------------------
    @property
    def hybrid_cache_mode(self):
        ''' :return: the evaluator's current hybrid cache mode, decide when to use GPU deformation instead of caching.  '''
        self.check_plugin()
        return cmds.cacheEvaluator(query=True, hybridCacheMode=True)

    @hybrid_cache_mode.setter
    def hybrid_cache_mode(self, new_value):
        '''
        Give the evaluator a new hybrid cache mode
        :param new_value: new value for hybrid cache mode, must be one of ['disabled', 'smp', 'all']
        '''
        self.check_plugin()
        
        try:
            cmds.cacheEvaluator(hybridCacheMode = new_value)
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedHybridMode' ].format(ex) )

    #----------------------------------------
    @property
    def resource_state(self):
        '''
        :return: String representing current resource usage compared to the limits
            unlimited   Usage is not being checked
            out         No Memory Left - 100% hit
            low         Between 90% and 100% usage
            okay        Less than 90% usage
        '''
        self.check_plugin()
        return cmds.cacheEvaluator( resourceUsage=True, query=True )

    #----------------------------------------
    @property
    def safe_mode_triggered(self):
        ''':return: the evaluator's safe mode triggered value (a read-only value)'''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator( safeModeTriggered=True, query=True )))

    #----------------------------------------------------------------------
    @property
    def safe_mode_messages(self):
        ''':return: The messages, if safe mode was triggered. Otherwise returns None. (a read-only value)'''
        self.check_plugin()
        if self.safe_mode_triggered:
            return cmds.cacheEvaluator(query=True, safeModeMessages=True)

        return None

    #----------------------------------------
    @property
    def safe_mode(self):
        ''':return: the evaluator's safe mode value'''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator( safeMode=True, query=True )))

    @safe_mode.setter
    def safe_mode(self, new_value):
        '''
        Give the evaluator a new safe mode state
        :param new_value: New safe mode state for the evaluator
        '''
        self.check_plugin()
        if self.safe_mode == new_value:
            return

        
        try:
            cmds.cacheEvaluator( safeMode=new_value )
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedSafe' ].format(ex) )

    #----------------------------------------
    @property
    def hud(self):
        ''':return: the evaluator's HUD display state value'''
        assert self is not None
        return cmds.optionVar(query=CachePreferenceHud().ov_id)

    @hud.setter
    def hud(self, new_value):
        '''
        Set the HUD display state for the evaluator. (Actually it's an optionVar but it only
        applies to this evaluator so the effect is the same.)
        :param new_value: New HUD display state for the evaluator
        '''
        if self.hud == new_value:
            return

        
        try:
            cmds.optionVar( intValue=(CachePreferenceHud().ov_id,new_value) )
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedHud' ].format(ex) )

    #----------------------------------------
    @property
    def resource_guard(self):
        ''':return: the evaluator's resource guard state value'''
        assert self is not None
        return cmds.optionVar(query=CachePreferenceResourceGuard().ov_id)

    @resource_guard.setter
    def resource_guard(self, new_value):
        '''
        Set the resource guard state for the evaluator. (Actually it's an optionVar but it only
        applies to this evaluator so the effect is the same.)
        :param new_value: New resource guard state for the evaluator
        '''
        if self.resource_guard == new_value:
            return

        
        try:
            cmds.optionVar( intValue=(CachePreferenceResourceGuard().ov_id,new_value) )
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedResourceGuard' ].format(ex) )

    #----------------------------------------
    @property
    def memory_threshold(self):
        ''':return: the evaluator's resource guard state value'''
        assert self is not None
        return cmds.optionVar(query=CachePreferenceMemoryThreshold().ov_id)

    @memory_threshold.setter
    def memory_threshold(self, new_value):
        '''
        Set the memory threshold for the evaluator. (Actually it's an optionVar but it only
        applies to this evaluator so the effect is the same.)
        :param new_value: New memory threshold for the evaluator
        '''
        if self.memory_threshold == new_value:
            return

        
        try:
            cmds.optionVar( floatValue=(CachePreferenceMemoryThreshold().ov_id,new_value) )
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedThreshold' ].format(ex) )

    #----------------------------------------
    @property
    def discard_frames_out_of_range(self):
        ''':return: the evaluator's state value for discarding cache data outside the playback range'''
        assert self is not None
        return cmds.optionVar(query=CachePreferenceDiscardFramesOutOfRange().ov_id)

    @discard_frames_out_of_range.setter
    def discard_frames_out_of_range(self, new_value):
        '''
        Set the state for discarding cache data outside of the playback range for the evaluator.
        (Actually it's an optionVar but it only applies to this evaluator so the effect is the same.)
        :param new_value: New discard state for the evaluator
        '''
        if self.discard_frames_out_of_range == new_value:
            return

        
        try:
            cmds.optionVar( intValue=(CachePreferenceDiscardFramesOutOfRange().ov_id,new_value) )
        except Exception as ex:
            self.err( maya.stringTable['y_maya_plugin_evaluator_CacheEvaluatorManager.kFailedDiscard' ].format(ex) )

    #----------------------------------------
    @property
    def cached_frames(self):
        '''
        Get the list of frame ranges with valid cache data.
        For example, the result can be `[(0b01, 1, 3), (0b10, 7, 10), (0b11, 13, 15)]`.

        It suggests frame ranges `1:3` (frames 1,2,3), `7:10` (frames 7,8,9,10), and `13:15` (frames 13,14,15) are cached. 
        No other frames contain valid cache data.

        The cache-status represents whether the frame is valid on animation cache or dynamics cache when `layered_evaluation_active` is `true`.
        The encoding is:
        - `0b01` Only animation cache is valid
        - `0b10` Only dynamics cache is valid
        - `0b11` Both animation and dynamics cache are valid
        In the above example, it suggests:
        - Frame range `1:3` are only valid in animation cache.
        - Frame range `7:10` are only valid in dynamics cache.
        - Frame range `13:15` are valid in both.
        :rtype: list[tuple[int,int,int]]
        '''
        return maya.cmds.cacheEvaluator( q=True, cachedFrames=True )

    def get_valid_frames(self, layers_mask = CacheLayers.ALL):
        '''
        Utility to extract the frame ranges valid on the given layers.
        For example, the result can be `[(1,3), (8,9)]`, indicates frames 1,2,3,8,9 are cached.
        :return: Sorted sequence of closed-interval `[start, end]`, representing frames `start,...,end` were cached.
        :rtype: iterable[tuple[int,int]]
        :param integer layers_mask: Bit mask of cache layers to check, can be `0b01`, `0b10` or `0b11`
        - `0b01` Only animation cache is valid
        - `0b10` Only dynamics cache is valid
        - `0b11` Both animation and dynamics cache are valid
        '''
        max_layer = int(self.layered_evaluation_active)
        max_layers_mask = (1 << (max_layer+1)) - 1
        layers_mask = layers_mask & max_layers_mask
        valid_frames = maya.cmds.cacheEvaluator( q=True, cachedFrames=True )

        if len(valid_frames) == 0 :
            return
        prev = None
        for current in valid_frames :
            if (current[0] & layers_mask) != layers_mask :
                continue
            if prev == None :
                prev = (current[1], current[2])
            elif (prev[1] + 1 == current[1]) :
                prev = (prev[0], current[2])
            else :
                yield prev
                prev = (current[1], current[2])
        if (prev != None) :
            yield prev

    #----------------------------------------
    @property
    def debugging(self):
        ''':return: the debugging state of the object, uses the combination of the parent class and the global cache preference state'''
        assert self is not None
        return EvaluatorManager.debugging or CP_DBG.debugging
# ===========================================================================
# Copyright 2022 Autodesk, Inc. All rights reserved.
#
# Use of this software is subject to the terms of the Autodesk license
# agreement provided at the time of installation or download, or which
# otherwise accompanies this software in either electronic or hard copy form.
# ===========================================================================
