import maya
maya.utils.loadStringResourcesForModule(__name__)

'''
Implementation of the elements of the toolkit UI controlling caching preferences
'''
from builtins import range
import json
from functools import partial
import maya.cmds as cmds
from maya.common.utils import Singleton
from maya.common.ui import LayoutManager, callback_tool, scrollableMessageBox
from maya.analytics.Runner import Runner
from maya.plugin.evaluator.CacheUiBase import CacheUiBase
from maya.plugin.evaluator.cache_preferences import CachePreferenceEnabled
from maya.plugin.evaluator.cache_preferences import cache_preferences_initialize, cache_ui_enabled
from maya.debug.emModeManager import emModeManager
from maya.debug.correctnessUtils import CORRECTNESS_INVALIDATE
from maya.debug.cacheCorrectnessTest import cacheCorrectnessTest
from maya.plugin.evaluator.CacheEvaluatorManager import CacheEvaluatorManager, KEY_CACHE_MODE
from maya.plugin.evaluator.CacheEvaluatorManager import CACHE_STANDARD_MODE_VP2_HW, CACHE_STANDARD_MODE_VP2_SW
from maya.plugin.evaluator.CacheEvaluatorManager import CACHE_STANDARD_MODE_EVAL, CACHE_STANDARD_MODE_EVAL_SHAPES
from maya.app.evaluationToolkit.evaluation_toolkit_utilities import BUTTON_WIDTH, COLUMN_SPACING, ROW_SPACING, FILE_TEXT_FIELD_WIDTH, section_layout
from future.utils import with_metaclass

__all__ = [r'CacheUiToolkit']

#======================================================================
# These tuples represent cache performance test information:
#       1) the nice name given to the particular caching configuration (used to label the analytic)
#       2) the description of the caching configuration
#       3) the configuration data sent to the CacheEvaluatorManager to set that mode
CACHE_PERFORMANCE_MODES = [
    (r'Baseline',     maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kBaselineCachePerformance'   ],                 {})
,   (r'Evaluation',   maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kEvaluationCachePerformance' ],        {})
,   (r'VP2 Software', maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kVP2SoftwareCachePerformance'], {})
,   (r'VP2 Hardware', maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kVP2HardwareCachePerformance'], {})
]

#======================================================================
# List of all of the cache correctness test types, indexed with labels and annotations
#    [0] = Name of test
#    [1]   'text' {Description of test
#          'mode' Caching modes, for cache correctness tests
#          'test' Test type, for backgrond evaluation tests
#          'type' Isolation type, for background isolation tests
KEY_MODE    = r'mode'
KEY_TEST    = r'test'
KEY_TEXT    = r'text'
KEY_TYPE    = r'type'
CORRECTNESS = r'correctness'
ISOLATION   = r'isolation'
CACHE_CORRECTNESS_DATA = [
    [r'VP2 Hdw'  , { KEY_TEXT : maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestVP2Hdw'   ]
                   , KEY_MODE : [{ KEY_CACHE_MODE : CACHE_STANDARD_MODE_VP2_HW }] }
    ]
,   [r'VP2 Sft'  , { KEY_TEXT : maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestVP2Sft'   ]
                   , KEY_MODE : [{ KEY_CACHE_MODE : CACHE_STANDARD_MODE_VP2_SW }] }
    ]
,   [r'DB All'   , { KEY_TEXT : maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestDBAll'    ]
                   , KEY_MODE : [{ KEY_CACHE_MODE : CACHE_STANDARD_MODE_EVAL }] }
    ]
,   [r'DB Shp'   , { KEY_TEXT : maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestDBShapes' ]
                   , KEY_MODE : [{ KEY_CACHE_MODE : CACHE_STANDARD_MODE_EVAL_SHAPES }] }
    ]
,   [r'BG CC'    , { KEY_TEXT : maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestBGCC'     ]
                   , KEY_TEST : CORRECTNESS }
    ]
,   [r'BG CI AA' , { KEY_TEXT : maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestBGCIAA'   ]
                   , KEY_TEST : ISOLATION, KEY_TYPE : r'animatedAttributes' }
    ]
,   [r'BG CI AN' , { KEY_TEXT : maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestBGCIAN'   ]
                   , KEY_TEST : ISOLATION, KEY_TYPE : r'animatedNodes' }
    ]
,   [r'BG CI SA' , { KEY_TEXT : maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestBGCISA'   ]
                   , KEY_TEST : ISOLATION, KEY_TYPE : r'staticAndAnimated' }
    ]
]
# Use this dictionary construction trick to ensure that a consistent ordering can be maintained
CACHE_CORRECTNESS_TESTS = { data[0] : data[1] for data in CACHE_CORRECTNESS_DATA }

#======================================================================
USE_VERBOSE_CORRECTNESS_TESTS = False

#======================================================================
# Label for tests that have not been run yet
TEST_NOT_RUN = maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kTestNotRun' ]

#======================================================================
def get_default_directory():
    '''Get a reasonable default directory for temporary output.'''
    from os import getenv as os_getenv
    default_path = os_getenv(r'MAYA_DEBUG_DIRECTORY')
    if default_path is None:
        from tempfile import gettempdir as tempfile_gettempdir
        default_path = tempfile_gettempdir()
    from os import path as os_path
    return os_path.normpath( default_path )

#======================================================================
def run_cache_performance_test():
    """
    Run the cache performance test on the current scene. Return a
    dictionary of NAME : (SPEED, MEMORY)
        NAME   = Name of the caching configuration
        SPEED  = fps of the playback
        MEMORY = Mb reported as being in use by the cache evaluator
    output will be shown in the script editor window.
    """
    returned_values = {}
    runner = Runner()
    runner.analytics = [r'CachePerformance']
    runner.return_json = True
    results = runner.run()
    try:
        # Highly dependent on the formatting of the analytic runner results
        full_output = results[r'analytic_run'][None][r'analytics'][r'CachePerformance'][r'output']

        # Print the detailed result in the script editor
        print(json.dumps(full_output))

        baseline_output = full_output[r'baseline']
        returned_values[CACHE_PERFORMANCE_MODES[0][0]] = (baseline_output[r'playback'], 0.0, 0.0, 0.0, 0.0)

        caching_output = full_output[r'caching']
        for output in caching_output:
            configuration_name = output[r'configuration_name']
            frames_cached = 0
            for interval in output[r'frames_cached']:
                frames_cached = frames_cached + interval[1] - interval[0] + 1
            # Cherry-pick the two interesting pieces of information for this summary
            play_fps = output[r'cached_playback']
            memory = output[r'cached_data'][r'Total'][r'memory'] / frames_cached
            fill_play_fps = output[r'filling_playback']
            background_fps = frames_cached / output[r'fill_time']
            flush_time = output[r'evacuation_time'] / frames_cached

            # Only record the data if it is in the list of modes of interest
            for (name,_,_) in CACHE_PERFORMANCE_MODES[1:]:
                if name == configuration_name:
                    returned_values[name] = (play_fps, memory, fill_play_fps, background_fps, flush_time)
                    break
    except Exception:
        # If no output found then the run did not complete successfully
        raise RuntimeError( maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kAnalyticRunFailed'] )

    return returned_values

#======================================================================
def run_cache_test(test_type, verbose):
    '''
    Run the named cache correctness test.
    The test information is drawn from the test info in CACHE_CORRECTNESS_TESTS.

    :param test_type: Test type - from the keys of CACHE_CORRECTNESS_TESTS
    :param verbose: True means add more detail to the output
    :return: a 2-tuple with the number of errors found and the JSON error details
    '''
    assert test_type in CACHE_CORRECTNESS_TESTS
    test = CACHE_CORRECTNESS_TESTS[test_type]

    # There are two types of tests - cache correctness (which have a caching KEY_MODE)
    # and background evaluation (which have a set of arguments to dbpeek)
    if KEY_MODE in test:
        details = cacheCorrectnessTest(verbose=verbose
                    , modes=test[KEY_MODE]
                    , em_setup=CORRECTNESS_INVALIDATE)
        try:
            if verbose:
                error_count = len(list(list(details.values())[0].values()))
            else:
                error_count = sum(details.values())
        except KeyError:
            error_count = 0
    else:
        if test[KEY_TEST] == r'correctness':
            different_time = cmds.currentTime(query=True) + 1.0
            args = [r'test=correctness', r'time={}'.format(different_time)]
            key_name = r'context correctness'
        else:
            assert test[KEY_TEST] == r'isolation'
            args = [r'test=isolation', r'isolationType={}'.format( test[KEY_TYPE] )]
            key_name = r'context isolation'

        if verbose:
            args += [r'verbose']

        with emModeManager() as emMgr:
            emMgr.rebuild( include_scheduling=True )
            details = json.loads(cmds.dbpeek( op=r'context', a=args ))
            try:
                error_count = len(details[key_name][r'errors'])
            except KeyError:
                error_count = 0

    return (error_count, details)

#======================================================================
class CacheUiToolkit(with_metaclass(Singleton, CacheUiBase)):
    '''
    Class managing the caching UI elements provided by the evaluation toolkit.

    :member preferences: CachePreferences object that handles updating the actual preference values
    :member ui_key: Unique identifier for this UI object. Used for smart deletion from CONTROLS dictionary
    :member widgets: Dictionary of widgets used by the UI (KEY=widget_id, VALUE=ui control name)
    :member mode_change_job: scriptJob ID for the customEvaluatorChanged callback
    '''

    def reset_widgets(self):
        '''
        Reset the widget names to uninitialized values
        '''
        self.widget_root = None
        self.widget_mon = None
        self.widget_mon_detail = None
        self.widget_mon_output = None
        self.widget_perf_speed = {}
        self.widget_perf_memory = {}
        self.widget_perf_fg_fill = {}
        self.widget_perf_bk_fill = {}
        self.widget_perf_flush = {}
        self.widget_corr_results = {}
        self.widget_corr_verbose = {}
        self.widget_corr_details_results = {}

        self.correctness_details = {}

    def __init__(self):
        '''
        Nothing to do here; the elements are created on demand and this is a persistent singleton
        '''
        super(CacheUiToolkit, self).__init__()
        
        self.mode_change_job = None

        # List of widgets created by the UI that need to be accessed by callbacks
        self.widget_root = None
        self.widget_mon = None
        self.widget_mon_detail = None
        self.widget_mon_output = None
        self.widget_perf_speed = {}
        self.widget_perf_memory = {}
        self.widget_perf_fg_fill = {}
        self.widget_perf_bk_fill = {}
        self.widget_perf_flush = {}
        self.widget_corr_results = {}
        self.widget_corr_verbose = {}
        self.widget_corr_details_results = {}

        self.correctness_details = {}
        self.context_monitor_enabled = False
        self.context_monitor_verbose = False
        from os import path as os_path
        self.context_monitor_file = os_path.join( get_default_directory(), r'ContextMonitor.json' )

        # Unique ID used for client notifications from CachePreferences()
        self.ui_key = r'cache_preferences_in_toolkit'

        # Make sure the prefs have already been set up
        cache_preferences_initialize()

    #----------------------------------------------------------------------
    def create_validation_ui(self):
        '''Create the layout section implementing the subset of cache validation features'''
        

        # Creating a master root layout allows enabling and disabling of the entire section in one command
        self.widget_root = cmds.columnLayout(adjustableColumn=True)

        with LayoutManager( self.widget_root ):

            with LayoutManager( cmds.frameLayout(label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCachingPerformance' ], **section_layout(True))):
                #----------------------------------------
                #
                # Performance test
                #
                cmds.button( label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kRunCachePerformanceTest' ]
                           , width=BUTTON_WIDTH
                           , command=callback_tool(self, self.callback_run_cache_performance_test) )

                with LayoutManager( cmds.rowColumnLayout( numberOfColumns=6
                                                        , columnAlign=[ (1, r'center')
                                                                    , (2, r'right')
                                                                    , (3, r'right')
                                                                    , (4, r'right')
                                                                    , (5, r'right')
                                                                    , (6, r'right')
                                                                    ]
                                                        , columnSpacing=[(i+1, COLUMN_SPACING) for i in range(6)]
                                                        , rowSpacing=[(1, ROW_SPACING)]
                                                        ) ):

                    cmds.text( font=r'boldLabelFont', label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestType' ] )
                    cmds.text( font=r'boldLabelFont', label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestSpeed' ] , annotation=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestSpeedAnnotation' ])
                    cmds.text( font=r'boldLabelFont', label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestMemory' ] , annotation=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestMemoryAnnotation' ])
                    cmds.text( font=r'boldLabelFont', label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestForegroundFill' ] , annotation=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestForegroundFillAnnotation' ])
                    cmds.text( font=r'boldLabelFont', label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestBackgroundFill' ] , annotation=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestBackgroundFillAnnotation' ])
                    cmds.text( font=r'boldLabelFont', label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestFlush' ] , annotation=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestFlushAnnotation' ])

                    for (name, description, _) in CACHE_PERFORMANCE_MODES:
                        cmds.text( label=name, annotation=description )
                        self.widget_perf_speed[name]  = cmds.text( label=TEST_NOT_RUN )
                        self.widget_perf_memory[name] = cmds.text( label=TEST_NOT_RUN )
                        self.widget_perf_fg_fill[name] = cmds.text( label=TEST_NOT_RUN )
                        self.widget_perf_bk_fill[name] = cmds.text( label=TEST_NOT_RUN )
                        self.widget_perf_flush[name]  = cmds.text( label=TEST_NOT_RUN )

            #----------------------------------------
            #
            # Correctness tests
            #
            correctness_columns = 4 if USE_VERBOSE_CORRECTNESS_TESTS else 3
            with LayoutManager(cmds.frameLayout(label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCachingTests' ], **section_layout(True))):
                with LayoutManager(cmds.rowColumnLayout( numberOfColumns=correctness_columns
                                                       , adjustableColumn=(correctness_columns-1)
                                                       , columnAlign=[(i+1, r'center') for i in range(correctness_columns-1)]
                                                       , columnSpacing=[(i+1, COLUMN_SPACING) for i in range(correctness_columns-1)]
                                                       , rowSpacing=[(i+1, ROW_SPACING) for i in range(8)]
                                                       ) ):

                    # Headings to label the error count and verbose checkboxes.
                    # They're all the same; using headings avoids redundancy.
                    error_label = maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheCorrectnessErrorLabel'  ]
                    verbose_annotation = maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheCorrectnessVerboseAnnotation' ]
                    if USE_VERBOSE_CORRECTNESS_TESTS:
                        cmds.text( label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kVerboseDetailLabel'], annotation=verbose_annotation )
                    cmds.text( label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kTestLabel'] )
                    cmds.text( label=error_label )
                    cmds.text( label='' )

                    button_label = maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheCorrectnessButtonLabel'  ]
                    for test_name, test_details in list(CACHE_CORRECTNESS_TESTS.items()):
                        if USE_VERBOSE_CORRECTNESS_TESTS:
                            self.widget_corr_verbose[test_name] = cmds.checkBox( label='', annotation=verbose_annotation, value=False )
                        else:
                            self.widget_corr_verbose[test_name] = None
                        cmds.button( label=button_label.format(test_name)
                                   , annotation=test_details[KEY_TEXT]
                                   , width=BUTTON_WIDTH
                                   , command=callback_tool(self, partial(self.callback_run_cache_correctness_tests, test_type=test_name)) )
                        self.widget_corr_results[test_name] = cmds.text( label=TEST_NOT_RUN, width=BUTTON_WIDTH )
                        self.correctness_details[test_name] = TEST_NOT_RUN
                        self.widget_corr_details_results[test_name] = cmds.button( label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheCorrectnessDetail' ]
                                                                                 , width=BUTTON_WIDTH
                                                                                 , enable=False
                                                                                 , command=callback_tool(self, partial(self.callback_show_cache_correctness_test_details, test_type=test_name)) )

            #----------------------------------------
            #
            # Context monitor
            #
            with LayoutManager(cmds.frameLayout(label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCachingContextMonitor' ], **section_layout(True))):
                with LayoutManager(cmds.rowColumnLayout( numberOfColumns=2
                                                    , columnAlign=[ (1, r'right'), (2, r'center')]
                                                    , columnSpacing=[2, COLUMN_SPACING]
                                                    , rowSpacing=[(i+1, ROW_SPACING) for i in range(2)]
                                                    ) ):

                    #----------------------------------------
                    self.widget_mon = cmds.checkBoxGrp( numberOfCheckBoxes=2
                                                    , label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kContextMonitorLabel' ]
                                                    , label1=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kContextMonitorEnable' ]
                                                    , changeCommand1=callback_tool(self, self.callback_update_context_monitor_state)
                                                    , label2=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kcontext_monitor_verbose' ]
                                                    , changeCommand2=callback_tool(self, self.callback_update_context_monitor_state)
                                                    )
                    self.widget_mon_detail = cmds.button( label=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kContextMonitorDetail' ]
                                                        , width=BUTTON_WIDTH
                                                        , enable=False
                                                        , command=callback_tool(self, self.callback_show_context_monitor_results)
                                                        )
                    self.widget_mon_output = cmds.textField( width=FILE_TEXT_FIELD_WIDTH
                                                        , text=self.context_monitor_file
                                                        , enterCommand=callback_tool(self, self.callback_update_context_monitor_output)
                                                        )
                    cmds.symbolButton( image=r'navButtonBrowse.png'
                                    , command=callback_tool(self, self.callback_choose_context_monitor_output) )

        self.monitor_window()

        CachePreferenceEnabled().add_client( self, callback_tool(self, self.callback_update_enabled) )
        self.plugin_state_change( new_state=CacheEvaluatorManager().plugin_loaded )
        self.mode_change_job = cmds.scriptJob(event=(r'customEvaluatorChanged', callback_tool(self, self.callback_update_enabled)))

        # Automatically remove this class when the parent control is deleted
        cmds.scriptJob( uiDeleted=(self.widget_root, callback_tool(self, self.callback_ui_deleted)) )

    #----------------------------------------------------------------------
    def is_ui_active(self):
        '''
        :return: True if the layout UI is still active. This is needed to avoid timing problems caused by the
        fact that the UI deletion callback is put onto the idle queue and may occur after idle update events.
        '''
        return self.widget_root is not None and cmds.columnLayout( self.widget_root, query=True, exists=True )

    #----------------------------------------------------------------------
    def clear_results(self):
        '''
        Clear out all of the current results
        '''
        

        for key in self.correctness_details:
            self.correctness_details[key] = TEST_NOT_RUN

        for field in list(self.widget_corr_results.values()):
            cmds.text( field, edit=True, label=TEST_NOT_RUN )

        for field in list(self.widget_corr_details_results.values()):
            cmds.button( field, edit=True, enable=False )

    #----------------------------------------------------------------------
    def plugin_state_change(self, new_state):
        '''
        Called when the plug-in state changed to loaded or unloaded. Updates the UI appearance to
        reflect the new state.
        :param new_state: True if the plug-in was just loaded, False if just unloaded
        '''
        
        assert self.widget_root is not None

        cmds.columnLayout( self.widget_root, edit=True, visible=new_state )

    #----------------------------------------------------------------------
    @staticmethod
    def callback_update_visibility(tool):
        '''
        Invoked when some external agent could affect the visibility of the widgets.
        e.g. the opening of a frame layout, which automatically makes all children visible
        '''
        tool.callback_update_plugin_state( tool=tool, new_state=CacheEvaluatorManager().plugin_loaded )

    #----------------------------------------------------------------------
    @staticmethod
    def callback_update_enabled(tool):
        '''
        Callback to refresh the enabled state of the cache tests to match the cache evaluator state.
        :param tool: CacheUiToolkit object to be updated
        '''
        
        if tool.is_ui_active():
            cmds.columnLayout( tool.widget_root, edit=True, enable=cache_ui_enabled() )

    #----------------------------------------------------------------------
    @staticmethod
    def format_time(seconds):
        '''
        :param float seconds: time delta value in seconds
        :return: formated string in ms, us, or ns with at least 3 effective digit
        :rtype: str

        >>> format_time(0)
        '0'
        >>> format_time(314.2)
        '314s'
        >>> format_time(31.42e-3)
        '31.4ms'
        >>> format_time(0.3142e-3)
        '314us'
        >>> format_time(3.142e-9)
        '3.14ns'
        >>> format_time(0.3142e-9)
        '0.314ns'
        >>> format_time(3.142e-13)
        '0'
        '''

        for unit, suffix in [ (1e0, r's'), (1e-3, r'ms'), (1e-6, r'us'), (1e-9, r'ns') ]:
            val = seconds / unit
            if val >= 100:
                return r'{:.0f}{}'.format(val, suffix)
            elif val >= 10:
                return r'{:.1f}{}'.format(val, suffix)
            elif val >= 1:
                return r'{:.2f}{}'.format(val, suffix)

        if seconds < 1e-12:
            return r'0'
        else:
            return r'{:.3f}{}'.format(val, suffix)

    #----------------------------------------------------------------------
    @staticmethod
    def callback_run_cache_performance_test(tool):
        '''
        Invoked from the Cache Performance button. Walks through all of the cache performance
        tests and runs them, adding the results to the widgets.
        '''
        

        for (run_type, info) in run_cache_performance_test().items():
            cmds.text( tool.widget_perf_speed[run_type], edit=True, label=r'{0:4.1f}'.format( info[0] ) )
            cmds.text( tool.widget_perf_memory[run_type], edit=True, label=r'{0:.2g}MB'.format( info[1] ) )
            cmds.text( tool.widget_perf_fg_fill[run_type], edit=True, label=r'{0:4.1f}'.format( info[2] ) )
            cmds.text( tool.widget_perf_bk_fill[run_type], edit=True, label=r'{0:4.1f}'.format( info[3] ) )
            cmds.text( tool.widget_perf_flush[run_type], edit=True, label=tool.format_time( info[4] ) )

    #----------------------------------------------------------------------
    @staticmethod
    def callback_update_context_monitor_state(tool):
        '''
        Update the context monitor state based on the current settings
        '''
        

        enabled = cmds.checkBoxGrp( tool.widget_mon, query=True, value1=True )
        verbose = cmds.checkBoxGrp( tool.widget_mon, query=True, value2=True )

        # Construct the argument to set the new state
        verbose_options = []
        if enabled:
            if verbose:
                verbose_options = [r'verbose']
            tool.context_monitor_file = cmds.textField(tool.widget_mon_output, query=True, text=True).strip()

        if enabled and not tool.context_monitor_enabled:
            # Turning on the monitor
            cmds.dbpeek( op=r'context', a=r'contextMonitor=off' )
            cmds.dbpeek( op=r'context', a=[r'contextMonitor=on']+verbose_options, of=tool.context_monitor_file )
        elif not enabled and tool.context_monitor_enabled:
            # Turning off the monitor
            cmds.dbpeek( op=r'context', a=r'contextMonitor=off' )
        elif verbose != tool.context_monitor_verbose:
            # Changing the verbosity
            cmds.dbpeek( op=r'context', a=r'contextMonitor=off' )
            cmds.dbpeek( op=r'context', a=[r'contextMonitor=on']+verbose_options, of=tool.context_monitor_file )
        else:
            # Nothing is changing, bail early
            return
        tool.context_monitor_enabled = enabled
        tool.context_monitor_verbose = verbose

        # Selectively disable controls that are no longer relevant
        cmds.button( tool.widget_mon_detail, edit=True, enable=(not enabled) )

    #----------------------------------------------------------------------
    @staticmethod
    def callback_get_context_monitor_details(tool):
        '''
        Callback function to get the results from the context monitor for the scrollableMessageBox
        '''
        
        try:
            result = ''
            with open(tool.context_monitor_file, r'r') as cm_fd:
                result = cm_fd.read()
            return result
        except IOError:
            return maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kNoMonitor']

    #----------------------------------------------------------------------
    @staticmethod
    def callback_show_context_monitor_results(tool):
        '''
        Callback when the context monitor Details button is pressed
        '''
        

        scrollableMessageBox( title=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kContextMonitorDetailTitle' ]
                            ,   messageCallback=partial(tool.callback_get_context_monitor_details, tool=tool)
                            )

    #----------------------------------------------------------------------
    @staticmethod
    def callback_update_context_monitor_output(tool):
        '''
        Callback when the output folder for the context monitor changes.
        Since the context monitor is actively using the output it has to
        be disabled first, if necessary, then re-enabled with the new output.
        If not enabled then nothing is done yet.
        '''
        

        if cmds.checkBoxGrp( tool.widget_mon, query=True, value1=True ):
            cmds.dbpeek( op=r'context', a=r'contextMonitor=off' )
            tool.callback_update_context_monitor_state( tool )

    #----------------------------------------------------------------------
    @staticmethod
    def callback_choose_context_monitor_output(tool):
        '''
        Callback when the output folder browser button is hit. If not canceled
        then the context monitor is disabled, then re-enabled with the new
        file selected as output.
        '''
        

        current_file = cmds.textField(tool.widget_mon_output, query=True, text=True)
        from os import path as os_path
        result = cmds.fileDialog2(
                      caption=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kChooseContextMonitorOutputFile' ]
                    , fileMode=0
                    , okCaption=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kContextMonitorChooseButton' ]
                    , startingDirectory=os_path.dirname(current_file + r'/')
                    )
        if result:
            assert len(result) == 1
            chosen_file = os_path.normpath(result[0])
            cmds.textField(tool.widget_mon_output, edit=True, text=chosen_file)
            tool.callback_update_context_monitor_output( tool )

    #----------------------------------------------------------------------
    @staticmethod
    def callback_run_cache_correctness_tests(tool, test_type):
        '''
        Invoked from one of the Cache Correctness buttons. Selects the test to be run,
        runs it, then adds the results to the widgets.
        '''
        

        if USE_VERBOSE_CORRECTNESS_TESTS:
            verbose = cmds.checkBox( tool.widget_corr_verbose[test_type], query=True, value=True )
        else:
            verbose = False
        (error_count, error_details) = run_cache_test( test_type, verbose )
        error_details_string = json.dumps(error_details, indent=4, separators=(',', ': '))
        tool.correctness_details[test_type] = error_details_string

        cmds.text( tool.widget_corr_results[test_type], edit=True, label=error_count )
        cmds.button( tool.widget_corr_details_results[test_type], edit=True, enable=True )

    #----------------------------------------------------------------------
    @staticmethod
    def callback_get_correctness_test_details(tool, test_type):
        '''
        Callback function for the scrollableMessageBox to get the detailed contents of the test output
        '''
        if test_type in tool.correctness_details:
            return str(tool.correctness_details[test_type]).split('\n')

        return maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCorrectnessDetailsUnavailable' ]

    #----------------------------------------------------------------------
    @staticmethod
    def callback_show_cache_correctness_test_details(tool, test_type):
        '''
        Invoked when the user clicks the info button to show cache correctness test details
        '''
        
        scrollableMessageBox( title=maya.stringTable['y_maya_plugin_evaluator_CacheUiToolkit.kCacheTestDetailFmt' ].format(test_type)
                            ,   messageCallback=partial(tool.callback_get_correctness_test_details, tool=tool, test_type=test_type)
                            )

    #----------------------------------------------------------------------
    @staticmethod
    def callback_ui_deleted(tool):
        '''
        Callback when the UI is deleted - cleans up the class variables.
        :param tool: CacheUiToolkit object attached to the UI that was deleted
        '''
        
        tool.reset_widgets()

        # Remove the callbacks used to monitor for optionVar changes
        CachePreferenceEnabled().remove_client( tool )

        if tool.mode_change_job is not None:
            cmds.scriptJob( kill=tool.mode_change_job )
            tool.mode_change_job = None
# ===========================================================================
# Copyright 2022 Autodesk, Inc. All rights reserved.
#
# Use of this software is subject to the terms of the Autodesk license
# agreement provided at the time of installation or download, or which
# otherwise accompanies this software in either electronic or hard copy form.
# ===========================================================================
