//**************************************************************************/
// Copyright (c) 2008 Autodesk, Inc.
// All rights reserved.
// 
// These coded instructions, statements, and computer programs contain
// unpublished proprietary information written by Autodesk, Inc., and are
// protected by Federal copyright law. They may not be disclosed to third
// parties or copied or duplicated in any form, in whole or in part, without
// the prior written consent of Autodesk, Inc.
//**************************************************************************/
// DESCRIPTION: Screen space ambient occlusion - main pass.
// AUTHOR: Mauricio Vives, converted to OGSFX by Eric Haines, July 2013
// CREATED: October 2008
//**************************************************************************/

#include "SSAO_Common.ogsfh"
#include "SSAO_Samples.ogsfh"

// Define this macro to use a second depth layer, for allowing hidden surfaces (the back faces)
// to contribute to the SSAO result.
// #define DOUBLE_LAYER

// The number of SSAO samples to use, between 1 and 64.
#ifndef NUM_SAMPLES
    #define NUM_SAMPLES 16
#endif

// The random normalized vector texture.
// NOTE: This is assumed to be 8x8 in an unsigned format.
uniform texture2D gRandomTex
<
    string UIName = "Random Texture";
    string ResourceName = "RandomVector.bmp";
>;

// The random texture2D sampler.
uniform sampler2D gRandomSamp = sampler_state
{
    Texture = <gRandomTex>;
    // TODO - can this be in a sampler? MinFilter = NearestMipMapNearest;
};

// The normal-depth buffer (first layer) and sampler.
uniform texture2D gNormalTex ;
uniform sampler2D gNormalSamp = sampler_state { Texture = <gNormalTex>; };
uniform texture2D gDepthTex ;
uniform sampler2D gDepthSamp = sampler_state { Texture = <gDepthTex>; };

#ifdef DOUBLE_LAYER
// The normal-depth buffer (second layer) and sampler.
uniform texture2D gDepthTex2 ;
uniform sampler2D gDepthSamp2 = sampler_state { texture = <gDepthTex2>; };
#endif

uniform bool MayaHwFogEnabled : fogEnabled = false;
uniform int MayaHwFogMode : fogMode = 0;
uniform float MayaHwFogStart : fogStart = 0.0f;
uniform float MayaHwFogEnd : fogEnd = 100.0f;
uniform float MayaHwFogDensity : fogDensity = 0.1f;
uniform float4 MayaHwFogColor : fogColor = { 0.5f, 0.5f, 0.5f , 1.0f };

// Pixel shader.
// NOTE: This expects screen quad vertex shader output.
// uniform vec4 PS_SSAO_Main(VS_TO_PS_ScreenQuad In) : COLOR0
GLSLShader PS_SSAO_Main
{
    void main()
    {
        vec2 UV = VSUV;
        UV.y = 1 - UV.y;

        // Get the normal and depth of the current pixel.
        float depth = texture2D(gDepthSamp, UV ).x;
    
        // Return white if the depth is less than or equal to zero.  This indicates the background,
        // which does not need any SSAO processing.
        if (depth < 1e-10)
        {
#if GL_ES
            gl_FragColor = vec4(1.0, 1.0, 1.0, 1.0);
#else
            colorOut = vec4(1.0, 1.0, 1.0, 1.0);
#endif
            return;
        }
        
        // Compute the depth scale from the depth of the current pixel and the view scale.  This
        // is the vector from the center of the screen to the corners of the screen in view space, at
        // the current depth.  This is used to convert the screen-space sampling radius (i.e. a fracttion
        // of the screen width and height) to a view-space radius.
        // NOTE: The average of the depth scale x and y components are used.  Multiplying by 1/2 to
        // compute the average cancels out multiplying by 2 to convert the depth scale from half the
        // view (center to edge) to the full view, so that is left commented out.
        vec2 gViewScale = 1.0 / abs(vec2(gProjection[0][0], gProjection[1][1]));
        vec2 depthScale = (gPerspectiveFlag ? depth : 1.0) * gViewScale;
        float radius = gSampleRadius * (depthScale.x + depthScale.y); // * 0.5 * 2.0 = 1.0
        
        // Reconstruct the view-space (3D) position of the current pixel from the depth, the depth
        // scale, and the normalized [0.0, 1.0] screen position.
        vec2 pos2D = UV * vec2(2.0, 2.0) - vec2(1.0, 1.0);
        vec3 pos3D = vec3(pos2D * depthScale, depth);
    
        // Sample the random texture2D to get a random normalized vector, based on the current screen
        // position. The texture2D is assumed to have the wrap addressing mode, have 8x8 dimensions,
        // and have an unsigned type (e.g. 32-bit RGBA).  The vector components must be scaled and
        // translated from unsigned values to signed values (i.e. times-two-minus-one).
        vec2 gFullScreenSize = gScreenSize / gTileScale;
        vec3 random = texture2D(gRandomSamp, vec2(UV.x, 1-UV.y) * gFullScreenSize / 8.0).xyz * 2.0 - vec3(1.0, 1.0, 1.0);

        // Get the normal of the current pixel.
        vec3 normal = texture2D(gNormalSamp, UV ).xyz * 2.0 - vec3(1.0, 1.0, 1.0);
 
        // Iterate the indicated number of samples to compute the total visibility contribution of the
        // samples.  The "sum" variable is a measure of visibility, the opposite of occlusion.
        float sum = 0.0;
        for (int i = 0; i < NUM_SAMPLES; i++)
        {
            // Get an offset from the offset array, which contains a set of random points inside a unit
            // sphere.  The offset is reflected by the per-pixel random vector, to replace banding
            // artifacts with (less objectionable) noise instead.  The reflected offset is then negated
            // if is on the opposite side of the surface normal, so that all sample points are on the
            // same side as the normal, i.e. a hemisphere of offsets instead of a sphere.  The offset
            // is then added to the 3D pixel position to create a 3D sample point.

			vec3 offset = reflect(GetOffset(i), random);
            if (dot(offset, normal) < 0.0) offset = -offset;
            vec3 sample3D = pos3D + offset * radius;
            
            // Project the 3D sample point to NDC space, by dividing by the depth scale of the sample
            // point.  Note that the depth scale of the sample point will differ slightly from the depth
            // scale computed above for the pixel position.  Only the 2D NDC components are needed.
            vec2 sampleNDC = sample3D.xy / ((gPerspectiveFlag ? sample3D.z : 1.0) * gViewScale);
            
            // Compute the UV coordinates of the NDC-space sample point (relative to the screen quad),
            // and sample the depth buffer.
            vec2 sampleUV = vec2(0.5, 0.5) * sampleNDC + vec2(0.5, 0.5);
            float sampleDepth = texture2D(gDepthSamp, sampleUV).x;
    
            // Compute the difference in depth between the sample point and the depth in the buffer,
            // If the occluder is behind the sample point, use full visibility for this sample.
            // Otherwise compute visibility based on the distance to the occluder.  Do nothing if the
            // original sample depth is less than or equal to zero.
            float vis1 = 1.0;
            float diff = max(sample3D.z - sampleDepth, 0.0);
            if (sampleDepth > 0.0)
            {
                // Reduce visibility based on the computed difference, normalized to the sampling
                // radius, with non-linear attenuation.  The greater the distance, the more occlusion.
                vis1 = diff > radius ? 1.0 : pow(1.0 - diff / radius, 2.0);
    
                // A more complex alternative, to be executed only if diff > 0.0:
                // Compute the distance between the 3D pixel position and the 3D position at the sampled
                // depth.  If this is larger than the sampling radius, use full visibility.  Otherwise,
                // compute the occlusion based on the normalized distance, i.e. relative to the sampling
                // radius.  A larger distance means a farther occluder, and thus more visibility.
                //
                // float dist = length(vec3(sample3D.xy, sampleDepth) - pos3D);
                // vis1 = min(pow(dist / radius, 2), 1.0);
            }
            
    #ifdef DOUBLE_LAYER
            // Repeat for the back faces, using the second normal-depth buffer.
            float vis2 = 1.0;
            sampleDepth = texture2D(gDepthSamp2, sampleUV).x;
            diff = max(sample3D.z - sampleDepth, 0.0);
            if (sampleDepth > 0.0)
            {
                vis2 = diff > radius ? 1.0 : pow(1.0 - diff / radius, 2.0);
            }
          
            // Select the value with the least visibility, and add it to the sum.
            sum += min(vis1, vis2);
    #else
            sum += vis1;
    #endif
        }
        
        // Compute the average visibility from the samples.
        float average = sum / NUM_SAMPLES;
        
       	if (MayaHwFogEnabled) {
			float fogFactor = 0.0f;
			if (MayaHwFogMode == 0) {
				fogFactor = saturate((MayaHwFogEnd - depth) / (MayaHwFogEnd - MayaHwFogStart));
			}
			else if (MayaHwFogMode == 1) {
				fogFactor = 1.0 / (exp(depth * MayaHwFogDensity));
			}
			else if (MayaHwFogMode == 2) {
				fogFactor = 1.0 / (exp(pow(depth * MayaHwFogDensity, 2)));
			}
			fogFactor = (1.0f - fogFactor) * MayaHwFogColor.a;
			average =  lerp(average, 1, fogFactor);		
		}
        
        // Return the average visibility as the grayscale color output of the shader.
#if GL_ES
        gl_FragColor = vec4(average, average, average, 1.0);
#else
        colorOut = vec4(average, average, average, 1.0);
#endif
    }
}


// Technique.
technique SSAO_Main
{
    pass p0
    {
        VertexShader (in VS_INPUT_ScreenQuad, out VS_TO_PS_ScreenQuad) = VS_ScreenQuad;
        PixelShader (in VS_TO_PS_ScreenQuad, out pixelOut) = PS_SSAO_Main;
    }
}
